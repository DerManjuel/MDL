{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DerManjuel/MDL/blob/main/MDL_Exercise5_distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2QN-sTuocjS_"
      },
      "source": [
        "# Medical Deep Learning\n",
        "## Exercise 5: Model Distillation & Ternary Nets\n",
        "\n",
        "The goal of this exercise is to implement methods that allow to compress deep learning models via model distillation and ternary weights. This enables the use of deep learning in medicine due to its real-time ability and implementation on weaker mobile devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK234fJ1iL37",
        "outputId": "785ace3b-2476-4e03-9e3d-966839e552cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# Set the device\n",
        "if torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cuda\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRUWE-KitK2d",
        "outputId": "b9826547-6b86-4a8e-8098-87a7e7bcf538"
      },
      "outputs": [],
      "source": [
        "#run pip install for pytorch flop counter before first use\n",
        "#!pip install onnx wget\n",
        "#!pip install --upgrade git+https://github.com/Lyken17/pytorch-OpCounter.git\n",
        "\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import shutil,gzip\n",
        "#import wget\n",
        "\n",
        "#some functions to count unique parameters and sparsity are provided\n",
        "def countParameters(net):\n",
        "    model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
        "    params = sum([p.numel() for p in model_parameters])\n",
        "    return params\n",
        "\n",
        "def countUnique(net):\n",
        "    unique = 0\n",
        "    for m in net.modules():\n",
        "        if(isinstance(m,nn.Conv2d)):\n",
        "            unique += len(np.unique(m.weight.data.cpu().flatten().numpy()))\n",
        "    return unique\n",
        "    #print('#unique',unique)\n",
        "\n",
        "def countSparsity(net):\n",
        "    count_nonzero = 0; count_zero = 0\n",
        "    for m in net.modules():\n",
        "        if(isinstance(m, nn.Conv2d)):\n",
        "            count_nonzero += torch.sum((m.weight.data!=0).float())\n",
        "            count_zero += torch.sum((m.weight.data==0).float())\n",
        "    return count_zero/(count_zero+count_nonzero)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "coxwH5pwcjTg"
      },
      "source": [
        "## Dataset\n",
        "We will use the data of the Patch Camelyon (tupac16) Challenge. It consists of $327\\,680$ color images extracted from histopathologic scans of lymph node sections. The task is to classify the presence of metastatic tissue (global binary labels are given). The images were preprocessed to a spatial dimension of $48\\times48$ and split to 65k for training and 16k for testing images. See [here](https://www.kaggle.com/competitions/histopathologic-cancer-detection/overview) for further details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0kHfFFKUtcTY"
      },
      "outputs": [],
      "source": [
        "#loading the patch-based wholeslide histopathology data (uint8) and converting it to torch tensors\n",
        "import os\n",
        "\n",
        "dataset_url = 'https://cloud.imi.uni-luebeck.de/s/sjjiReHqSnokJ2n/download'\n",
        "\n",
        "def get_data(data_url):\n",
        "    filename = './patchCamelyon8c.mat'\n",
        "    if not os.path.exists(filename):\n",
        "        #filename = wget.download(data_url)\n",
        "        pass\n",
        "\n",
        "get_data(dataset_url)\n",
        "\n",
        "\n",
        "data = scipy.io.loadmat('patchCamelyon8c.mat')\n",
        "\n",
        "img_train = torch.from_numpy(data['img_train'].astype('float32')/255)\n",
        "img_test = torch.from_numpy(data['img_test'].astype('float32')/255)\n",
        "\n",
        "label_train = torch.from_numpy(data['label_train']).long()\n",
        "label_test = torch.from_numpy(data['label_test']).long()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vfc1vm-AcjTj"
      },
      "source": [
        "Let's visualize an example for the two classes. You can run the cell multiple times, getting each time new random examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "1Qo6fpgEcjTk",
        "outputId": "e7e976b7-382b-4d5a-83ff-665f0cf0ae2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "index for no metastatic tissue: 19782\n",
            "index for metastatic tissue: 19992\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEhCAYAAADfxcKRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACD/UlEQVR4nO2dd3hUZdr/78lkZjKZ9N57QmihhCK9CUhRsa9tsa0iuiuy+yroq7CuC4qui7uu+uqquLosFsCKSAelt9BCQksgJKT3SaY/vz/8kXDPd1BQGRP2/lwX18Vz5z5nnjnnOc88c853vrdGKaVIEARBEATBS/j80h0QBEEQBOG/C1l8CIIgCILgVWTxIQiCIAiCV5HFhyAIgiAIXkUWH4IgCIIgeBVZfAiCIAiC4FVk8SEIgiAIgleRxYcgCIIgCF5FFh+CIAiCIHgVWXxcprS0tNDcuXNpw4YNl/R1tmzZQnPnzqX6+vofvY8VK1bQ3LlzPf4tJSWF7rrrrh+973N59dVXadGiRRAvLi4mjUbj8W+C0NmZN28effLJJ5f0NfLz82nu3LlUXFz8o/fxfXPJyJEjaeTIkT963+eyePFiWrhwoce/aTSa885Fws+MEi5LqqqqFBGpOXPmXNLXeeGFFxQRqaKioh+9j4ceekidbyju2bNHHTt27Efv+1y6d++uRowYAXGLxaK2bt2qKisrf5bXEYSOhMlkUlOnTr2kr/HRRx8pIlLr16//0fv4vrnk0KFD6tChQz++g+cwadIklZyc7PFvW7duVSUlJT/L6wjfj+8vuvIRhB+gT58+l/w1DAYDXXHFFZf8dQRB+HF069bNK68j84AX+aVXPx2FOXPmKCJSBw8eVL/61a9UUFCQioqKUnfffbeqr69nua2trWrWrFkqJSVF6XQ6FRcXp6ZPn67q6up+8HWmTp2qTCaTOnz4sBo3bpzy9/dXMTExav78+Uqp71beQ4YMUf7+/iozM1MtWrQI9nHmzBl1//33q/j4eKXT6VRKSoqaO3eustvtSimlioqKFBHBv7Pffo4eParuuusulZGRoYxGo4qLi1OTJ09W+/fvZ6/jdDrVn/70J5WVlaX8/PxUcHCw6tmzp1q4cCE7Zu7/zn77WbJkiRo7dqyKiYlRfn5+Kjs7Wz3++OOqubmZHQ9P+zj77Sc5ORm+tdXV1amZM2eq1NRUpdfrVWRkpJowYYI6fPjweY97cnIyvMbZbz9nj9c777zTll9ZWal+85vfqISEBKXX61VERIQaPHiwWr16dVvOnj171KRJk1RkZKTS6/UqNjZWTZw4se2bk6f9noU83JU6cuSIuvXWW9v2l52drV555ZXzvieh83L22tm3b5+68cYbVVBQkAoNDVWPPvqostvtqqCgQI0fP14FBASo5ORk9fzzz8M+Ghoa1O9//3s2Dz3yyCPs+vJ0bZ29+1dZWakefPBB1bVrV2UymVRkZKQaNWqU2rRpE7zWq6++qnJycpTJZFIBAQGqS5cuavbs2Uoppd555x2Pr3N23K9atUpdc801Kj4+XhkMBpWenq7uv/9+VVVVBcfjfHPJiBEj4K6lxWJRf/zjH1V2drYyGAwqLCxMjRw5Um3evPm8x33EiBEeX+fc43XudWk2m9uOscFgUKGhoSo3N1ctXry4Lef48ePqlltuUbGxsUqv16uoqCg1evRotXfv3vPu9yye5rcfmt8vF+TOhxs33HAD3XLLLXTvvffSgQMHaPbs2URE9PbbbxMRkVKKpkyZQmvXrqXZs2fTsGHDaP/+/TRnzhzaunUrbd26lQwGw/e+ht1up+uvv56mTZtG//M//0OLFy+m2bNnU2NjIy1dupQef/xxSkhIoL///e901113UY8ePSg3N5eIiMrLy2nAgAHk4+NDTz/9NKWnp9PWrVvp2WefpeLiYnrnnXcoNjaWVq5cSVdddRXde++9dN999xERUWRkJBERlZWVUXh4OD333HMUGRlJtbW19O6779LAgQNp79691KVLFyIiWrBgAc2dO5f+93//l4YPH052u50KCgransned999VFtbS3//+99p2bJlFBsbS0Tt31KOHj1KEydOpBkzZpDJZKKCggJ6/vnnaceOHbRu3ToiInrqqafIbDbTxx9/TFu3bm07Rmf35U5TUxMNHTqUiouL6fHHH6eBAwdSc3Mzbdq0ic6cOUPZ2dket1u+fDndeOONFBwcTK+++ioR0feepzvvvJP27NlDf/7znykrK4vq6+tpz549VFNTQ0REZrOZxo4dS6mpqfSPf/yDoqOjqby8nNavX09NTU3fe/49kZ+fT4MHD6akpCT6y1/+QjExMfT111/T7373O6qurqY5c+Zc9D6Fjs/NN99Md9xxBz3wwAO0evVqWrBgAdntdlqzZg1Nnz6d/vCHP9DixYvp8ccfp4yMDLr++uuJ6DtN14gRI+j06dP0xBNPUE5ODh06dIiefvppOnDgAK1Zs4Y0Gg1t3bqVRo8eTaNGjaKnnnqKiIiCgoKIiKi2tpaIiObMmUMxMTHU3NxMy5cvp5EjR9LatWvbNBZLliyh6dOn029/+1t68cUXycfHh44dO0b5+flERDRp0iSaN28ePfHEE/SPf/yD+vbtS0RE6enpRER0/PhxGjRoEN13330UHBxMxcXF9NJLL9HQoUPpwIEDpNPpfnAuccfhcNCECRPom2++oRkzZtDo0aPJ4XDQtm3b6NSpUzR48GCP27366qt0//330/Hjx2n58uU/eH5mzpxJ7733Hj377LPUp08fMpvNdPDgwbZ5gIho4sSJ5HQ6acGCBZSUlETV1dW0ZcuWH6WDu5D5/bLhl179dBTOrrwXLFjA4tOnT1d+fn7K5XIppZRauXKlx7wPPvhAEZF64403vvd1zn7TX7p0aVvMbreryMhIRURqz549bfGamhql1WrVzJkz22IPPPCACggIUCdPnmT7ffHFFxURtT0XvRjNh8PhUDabTWVmZqpHH320LT558mTVu3fv7932QjUfLpdL2e12tXHjxrZvfGf5Ps2H+zeDZ555RhERuwNxoZxP8+HpDkVAQICaMWPGefe1a9cuRUTqk08+OW/Oxdz5GD9+vEpISFANDQ0s7+GHH1Z+fn6qtrb2vK8jdD7Ozjd/+ctfWLx3796KiNSyZcvaYmfnh+uvv74tNn/+fOXj46N27tzJtv/4448VEakVK1a0xS5U8+FwOJTdbldjxoxR1113XVv84YcfViEhId+77YVqPs7OAydPnlREpD799NO2v33fXOJ+5+Nf//qXIiL15ptv/uD7cuf7NB/u12WPHj3UlClTzruv6upqRURtd4PPx/nmYvf57ULn98sB+bWLG9dccw1r5+TkkMViocrKSiKitm/s7r/AuOmmm8hkMtHatWt/8DU0Gg1NnDixre3r60sZGRkUGxvLNA5hYWEUFRVFJ0+ebIt98cUXNGrUKIqLiyOHw9H2b8KECUREtHHjxh98fYfDQfPmzaNu3bqRXq8nX19f0uv1dPToUTp8+HBb3oABA2jfvn00ffp0+vrrr6mxsfEH930uJ06coNtuu41iYmJIq9WSTqejESNGEBGx17kYvvrqK8rKyqIrr7zyR21/oQwYMIAWLVpEzz77LG3bto3sdjv7e0ZGBoWGhtLjjz9Or7/+etu3wB+DxWKhtWvX0nXXXUf+/v7svE6cOJEsFgtt27btp74loQMyefJk1u7atStpNJq265mofX5wnwd69OhBvXv3ZuNl/PjxpNFoLvhXbq+//jr17duX/Pz8yNfXl3Q6Ha1duxbmgfr6err11lvp008/perq6ot6j5WVlTRt2jRKTExse43k5GQi+mnzgJ+fH91zzz0/avsLZcCAAfTVV1/RrFmzaMOGDdTa2sr+HhYWRunp6fTCCy/QSy+9RHv37iWXy/WjX+/nmN87C7L4cCM8PJy1z96aPzvoampqyNfXt+0Rxlk0Gg3FxMSw23Hnw9/fn/z8/FhMr9dTWFgY5Or1erJYLG3tiooK+vzzz0mn07F/3bt3JyK6oIlh5syZ9NRTT9GUKVPo888/p+3bt9POnTupV69e7OKaPXs2vfjii7Rt2zaaMGEChYeH05gxY2jXrl0/+BrNzc00bNgw2r59Oz377LO0YcMG2rlzJy1btoyICC7iC6WqqooSEhJ+1LYXwwcffEBTp06lf/7znzRo0CAKCwujX//611ReXk5ERMHBwbRx40bq3bs3PfHEE9S9e3eKi4ujOXPmwELlh6ipqSGHw0F///vf4byeXaRe7IQvdA7cr3m9Xn/e+cF9Hti/fz+Ml8DAQFJKXdB4eemll+jBBx+kgQMH0tKlS2nbtm20c+dOuuqqq9j1eeedd9Lbb79NJ0+epBtuuIGioqJo4MCBtHr16h98DZfLRePGjaNly5bRY489RmvXrqUdO3a0LaZ/yjwQFxdHPj6X9iPsb3/7Gz3++OP0ySef0KhRoygsLIymTJlCR48eJaLv5v21a9fS+PHjacGCBdS3b1+KjIyk3/3udz/q8evPMb93FkTzcZGEh4eTw+GgqqoqtgBRSlF5eTn179//kr5+REQE5eTk0J///GePf4+Li/vBfbz//vv061//mubNm8fi1dXVFBIS0tb29fWlmTNn0syZM6m+vp7WrFlDTzzxBI0fP55KSkrI39//vK+xbt06Kisrow0bNrTd7SCin+QHQvSdbuX06dM/aR8XQkREBC1cuJAWLlxIp06dos8++4xmzZpFlZWVtHLlSiIi6tmzJy1ZsoSUUrR//35atGgRPfPMM2Q0GmnWrFltHyBWq5Xt232BGhoaSlqtlu6880566KGHPPYnNTX1ErxLobMSERFBRqOxTYvm6e8/xPvvv08jR46k1157jcU9fWjefffddPfdd5PZbKZNmzbRnDlzaPLkyXTkyJG2uxieOHjwIO3bt48WLVpEU6dObYsfO3bsB/v3fURGRtK3335LLpfrki5ATCYT/fGPf6Q//vGPVFFR0XYX5Oqrr6aCggIiIkpOTqa33nqLiIiOHDlCH374Ic2dO5dsNhu9/vrrRPTdl1j3eYAI54KfY37vLMji4yIZM2YMLViwgN5//3169NFH2+JLly4ls9lMY8aMuaSvP3nyZFqxYgWlp6dTaGjoefPc79ici0ajAbHll19+SaWlpZSRkeFxfyEhIXTjjTdSaWkpzZgxg4qLi6lbt27nfR2NRsP6cZb/+7//+96+Go3G874nIqIJEybQ008/TevWraPRo0d/b66n1/kx37SSkpLo4YcfprVr19LmzZvh7xqNhnr16kV//etfadGiRbRnzx4iIoqOjiY/Pz/av38/y//0009Z29/fn0aNGkV79+6lnJwc0uv1F91H4b+LyZMn07x58yg8PPwHF6bnG/ee5oH9+/fT1q1bKTEx0eO+TCYTTZgwgWw2G02ZMoUOHTpEycnJP/s88ENMmDCB/vOf/9CiRYsu+tHLj50HoqOj6a677qJ9+/bRwoULqaWlBb6AZWVl0f/+7//S0qVL2+YBou/MEt3ngXXr1lFzczOLXej8fjkgi4+LZOzYsTR+/Hh6/PHHqbGxkYYMGdL2a5c+ffrQnXfeeUlf/5lnnqHVq1fT4MGD6Xe/+x116dKFLBYLFRcX04oVK+j111+nhIQECgwMpOTkZPr0009pzJgxFBYWRhEREZSSkkKTJ0+mRYsWUXZ2NuXk5NDu3bvphRdegMcZV199NfXo0YP69etHkZGRdPLkSVq4cCElJydTZmYmEX337Z+I6OWXX6apU6eSTqejLl260ODBgyk0NJSmTZtGc+bMIZ1OR//+979p37598J7O7uP555+nCRMmkFarPe+H8IwZM+iDDz6ga6+9lmbNmkUDBgyg1tZW2rhxI02ePJlGjRp13mN39k7FBx98QGlpaeTn59f22ufS0NBAo0aNottuu42ys7MpMDCQdu7cSStXrmz7tcEXX3xBr776Kk2ZMoXS0tJIKUXLli2j+vp6Gjt2LBF9N/Hecccd9Pbbb1N6ejr16tWLduzYQYsXL4bXfPnll2no0KE0bNgwevDBByklJYWampro2LFj9Pnnn7dpjQSB6LvrYOnSpTR8+HB69NFHKScnh1wuF506dYpWrVpFv//972ngwIFE9N2437BhA33++ecUGxtLgYGB1KVLF5o8eTL96U9/ojlz5tCIESOosLCQnnnmGUpNTSWHw9H2Wr/5zW/IaDTSkCFDKDY2lsrLy2n+/PkUHBzcdqe3R48eRET0xhtvUGBgIPn5+VFqaiplZ2dTeno6zZo1i5RSFBYWRp9//rnHRzbnm0sCAwMh99Zbb6V33nmHpk2bRoWFhTRq1ChyuVy0fft26tq1K/3qV78677Hr2bMnLVu2jF577TXKzc0lHx8f6tevn8fcgQMH0uTJkyknJ4dCQ0Pp8OHD9N5779GgQYPI39+f9u/fTw8//DDddNNNlJmZSXq9ntatW0f79++nWbNmte3nzjvvpKeeeoqefvppGjFiBOXn59Mrr7xCwcHB7PUudH6/LPhF5a4diLPq83N/e65U+2/Yz1Vgt7a2qscff1wlJycrnU6nYmNj1YMPPnhRPh/ujBgxQnXv3h3iycnJatKkSSxWVVWlfve736nU1FSl0+lUWFiYys3NVU8++ST7jf+aNWtUnz59lMFgYD4fdXV16t5771VRUVHK399fDR06VH3zzTegKP/LX/6iBg8erCIiIpRer1dJSUnq3nvvVcXFxaw/s2fPVnFxccrHx4cp3rds2aIGDRqk/P39VWRkpLrvvvvUnj174BcgVqtV3XfffSoyMlJpNJoL8vl45JFHVFJSktLpdCoqKkpNmjRJFRQUfO+xLy4uVuPGjVOBgYHf6/NhsVjUtGnTVE5OjgoKClJGo1F16dJFzZkzR5nNZqWUUgUFBerWW29V6enpymg0quDgYDVgwADwZWloaFD33Xefio6OViaTSV199dWquLjYo/q9qKhI3XPPPW2/74+MjFSDBw9Wzz777Pe+L6Hzcb755mLmh+bmZvW///u/qkuXLkqv17f58Dz66KOqvLy8LS8vL6/NO4jO8fmwWq3qD3/4g4qPj1d+fn6qb9++6pNPPlFTp05lvwZ599131ahRo1R0dLTS6/UqLi5O3XzzzeALtHDhQpWamqq0Wi27nvLz89XYsWNVYGCgCg0NVTfddJM6deqUx2vgfHOJJ5+P1tZW9fTTT6vMzEyl1+tVeHi4Gj16tNqyZcv3Hvva2lp14403qpCQkLb55izufZo1a5bq16+fCg0NVQaDQaWlpalHH31UVVdXK6WUqqioUHfddZfKzs5u80DJyclRf/3rX5XD4Wjbj9VqVY899phKTExURqNRjRgxQuXl5Xmc3y50fu/saJRSyvtLHkEQBEEQ/luRX7sIgiAIguBVZPEhCIIgCIJXkcWHIAiCIAheRRYfgiAIgiB4FVl8CIIgCILgVS7Z4uPVV1+l1NRU8vPzo9zcXPrmm28u1UsJgnCZIPOGIPx3cElMxj744AOaMWMGvfrqqzRkyBD6v//7P5owYQLl5+dTUlLS927rcrmorKyMAgMD29zxBEHwLkopampq8kr9jLP8lHmDSOYOQfiluah541KYhwwYMEBNmzaNxbKzs9WsWbN+cNuSkhJFRPJP/sm/DvCvpKTkUkwRHvkp84ZSMnfIP/nXUf5dyLzxs9/5sNlstHv3bmYtS0Q0btw42rJlC+RbrVZWcEf9f8+z/C27KDAgoC1+5sgZtl1VcSnsKyElEmJBiRiz1vLCSaWFxZAT6qFo2vG6OtZe8+8NkDN4GJZ6P2bmhdDWb94EOUO7Y0G6yROGQSwkysHaqkkHOSfL8dgkBsey9vYDhyAnITIaYmkjekHMXM+PQ3lZJeR0H4E1YvZ+fZy13/zLvyAnIwetg2e/8D8QKzvKC1NVHKuAnLTYZIgdKOHHZvV6tC0/eqwYYvfcfjNrR4T7Qc6x42cgtm7Nboh1y05j7Uk34Zgx+jkgFpfJv/3X1mB9isPb9kCsS0YaxJwmXkPHR2Ni7WZzM11xwxCP1taXgoudN4jOP3dcHfV70vm01xJJ7Z7Otmtp4fU0iIisNjzedie+ZrSBH6dwX7zD4h+C12STvZy1rxh5BeRYtPh6zqJ61i4oKYecwACshr3v9CmIDckdytq1JcWQo3T4bbXBrSBa/tEiyBnYpy/E/AlLy9fX87m3qrEFcoyheOCdrTwvUB8COVYbfpxVN2AV2JAofg637siDnIBAnIeCAvn+qxWkUH01zgFXdI9h7bsevgZyyquxGvp7r34KsYggPqeFhmGhuXW7t0LMYedjMikkGHKuvxLH5ObNOyFW1cSvleTM9jpAVnsr/XXlAxc0b/zsi4/q6mpyOp0UHc0/yKKjo9vKkZ/L/Pnz6Y9//CPEAwMCKOicN9DkzwdtixEXB4H+JogFBeBBsFj5qDF52FeAh5i/hV+Eei3WHvE34HZ+dv5B5avFyclPhx9mAUZ8P4Emt8WHE/fl6f0Euu3LaMACbiY/D9t5OH4at5LxJiNO5kGBARBz75fOB/tu0BkgFuRhIDea3D4sPY4H7IO/23vU6/Ac+nrol/t2JiOeL0/HVHcB5zrAw7j1N+KHoftxsFvx08rjOTTh/p0mnuejwWNFRF57fHGx8wbR+ecOnY+BdD7tx9jgy9+r0xc/3JQTj7end27w5efYz8Piw+hhTNmJn3OTHx5vrafFh4Ffa0YdjjGjHs+5ez+JiPwN/DVbdbidp8WH1cU7ptd6GPt6HGNGD4sPi44fe4MvfoL76TwsPhzKLQf7rvHwXdrTcfBzO4a+Pni+dB7eo17L96/zsPjw9cH5y+B2vQeacD5rasGKt3pfD/tyH38ejoOnPpDbnObpHLqPj+9ez9Nx4NeKwdO5uIB545I9zHV/caWUxw7Nnj2bGhoa2v6VlJRcqi4JgtDBudB5g0jmDkHozPzsdz4iIiJIq9XCt5XKykr4VkP0XXlj93LLRETksBHZbW3N+BR+G0xZ8JuKAxeP9NW/voBYeDB/FBOox9cPi8G+lm8tYO2kVLzldfj4NojdPfM3rD1+7EDIWf7mUojt2YS3vMZM5LdOg5NiIaf4mzyINVIjaw8diY95tq5bi9utskCspqyetXcW7oec/fn4uOaue6awdkXzRMh57hkstW2+bx7EnnnhD6ytzDbI2X7kIMQWvf0Ja4dHhkDO6MFDIBaq498KuqdnQU5JSS3ErhiGx+GKgd1Ze/m/Poec2ES8lT45jJdOf2r2PyCn5thJiE1/5NcQ6zc+l7U1ej4VuJrw2+Cl5GLnDaLzzx1DBw8ho679m3hBKX9EZ25qct+EdBq8Q2XxUHbdZeDHRa/DKTQ5Bs9dXNccHsAvi+RjxWst/zS/jW9rwElO6fEOQ7AGb6Mc3bODtQP0+N0zs2s2xA4V8UVdZho+Ut22cxfEYiOxJHy3nnzsb1m9HnIGROLc5NDy921pxWPldOIdWKMOF67ZabySdV013mlptuLny5Ae/Jr/aj/Oe1Y/vAOUmdWDtW2teDfhbwv+AzFfhZKBgmIza9+UgeN24licv774gn8u+Xu4U9XSjOOo0YIxs+Kxyvqqtv/bHHjNnI+f/c6HXq+n3NxcKJl8tkywIAiCOzJvCMJ/F5fkp7YzZ86kO++8k/r160eDBg2iN954g06dOkXTpk27FC8nCMJlgMwbgvDfwyVZfNxyyy1UU1NDzzzzDJ05c4Z69OhBK1asoORk/PWBIAgCkcwbgvDfxCVZfBARTZ8+naZPn/6jt8/fsZf9OsIQwH8a1GsgPhdsbm6E2JScOyB26gj/GVpzOW73/GtvQOw3t9zE2k5ffGql8cNn0F99tIK1G2vx2WSLGWOmENxXVRX/SWn4gAjIiYrD2Da3Z37WUHym33fwUIjl5x2DWEYq19+kDEuBnIho1MNUuP2cbNSVIyBn7KQJEFv7Ff40ef2nG1j7iiF9ICc0ogxi8Ym8X/37doecaL8giO3dvJm1bbZ6yCHCZ8dDhvWDWE4O/8lsYxH+zM4/DM+9jvhz6KzUeMg5UYX9ignFn9VVV/JrICyW6xRcLhyP3uCnzhtERK3mZlK69ufSZrefaWo9mB/5+eBU6PDDa6SinmtSpozBn03qHGaI1VRVsbavh5/j+mvxnGvdfsnSPQ1/Nn2mpQ5imYk4Nlx2rosK9/DrrDOFRyAWHxjO92MKgZyGM/gT0+SEGIjVVPFrMt2Dbi7QhDqDUzX8+Hn4gRiNHd0TYoEBIRBbs45rwU6UoVDZ4eGXOkrD9XVRMahpOXoSf+L85Qo+927YgPoYf4qCWHIC6srqzVzr8unqlZCT3h01OeMGZrL28N45kHPw5FGI7a0ogJhBx8dDbEu7hsXlQK3M+ZDaLoIgCIIgeBVZfAiCIAiC4FVk8SEIgiAIgleRxYcgCIIgCF7lkglOfypNJ5rJZWgX8Fmj+DrJYkGzHWcA+t06TGg+lTyIC3I+f28V5Bw9VQ+xdRt5HZAew1CgGW5EcR85uZBs4GAU++yNRBHSxDuvg1jBLm5sU30axVJdslMgdnjnYdY+sA9ru2SkJEIsOAwNcRpbeb2EAZlYgyYoHRVh+Rt5TYiKYx5Eaj3QNO2qm9HnobmaC8KObj0AOT26oMHXzD9ww5+WGqwJU3zgOMT69uf70kWgGDEltQfE7M0owNqxhpvHGYwo/Iv2YDJm13JzrLHjB0HOiaAQiGk9GE4ZfbloTGMNdmt78PruJPgafEh3jk2400086MlSPzEOq+buzN8HsZpGLnw8WIxjJTcTRaE2ewNrx8TgOK89WgWxmgYuXg3R4rwXkRQOMZMfTu2RsVwofmK/BzF5FIpEi48Ws7bdgv0c0APFkVoDzseJbuZ8TTYUdq5dhWaHPm4W5XYX7rvoFNrwd+2BluE1LdwM0ObBQbfFhuO/oYmfw9ioEMhJiMFz0VjJt3MRbpfqQZwbEIBzR3QSf9/m+kzI2bYDhaMJoW7XewMed/8ITyUxcB5qMXNhfdfsrm3/b7WZifCjzCNy50MQBEEQBK8iiw9BEARBELyKLD4EQRAEQfAqsvgQBEEQBMGrdFjBaWVxHRl17RXyKvZxsWJTPQpJB01A11MX6rrIauSOh5NuQlfNL/+9BmKbdnNx2bYCdNCMiUR30VtuuJq1ozNRlBR7BfbhdA1WSd27hfchOB9P4ahxKAAddx13Ey0/VQo5MZGBEAs2omun3cKrjO77JB9yYvvicUgI4iLUqlbcd0MtCskCY7AEqI+eV29N74qVT4sO4/ELjeXr7ZQUtO7WOtBpsraJu+BmDewCOf4BePzee/kDiKUF8kHZoKohJ8mEA9fHTZcan4auiJqmFoidrkdRcpafW8VMd8NNNODsNFicViIfLW+fg8uO4273ARQsu/zwIEQn8fFysAiPrfLFa7L7EH68rS4UE+7asRdiWh8u+NNqURzZbGmAWEwsCmjf/+hj1v7mAFZAjjGiwHzicC6sN2jxO2tpOTp7xnpwWi4v5yLzfQUo2E3wIHzvNZA7GLvvh4iosgTPRVU1Hpsh47joVROIx/Soh7kjOZZfk6a4EMiJCcYxU1nJ3YI/34iVz4/vxOPXrxceh5cem8naJQewGm5FCApHXUE8FpGCDrhBOpz3IjxUfC+18mOzJr/dZdXu9FBa/jzInQ9BEARBELyKLD4EQRAEQfAqsvgQBEEQBMGryOJDEARBEASv0mEFp5ogX9Lo27tXfbKS/b14HwphHHWNEBt+y3CIBWdyAaNLh+KvO+69GmLx0Vxs9tLzf4OcgkNFEJt35EXW/uvbz2OfAtBJbu1XKHqtr+Ai18oydKrL7osllbsN5YKtqk9QUOXyUKc62IhiLLLwmKsKRaKWAtx/RTB36LQH4No3wYOzp7kKS4a7Wt221WEfuoxB0d3yVz5l7YzMVMj58D+fQcyq4WPkT4NmQU6rC8VWDc04Jjcf5GLfhPRIyGmown2VuznLvr7gNcj53b33QSwrB90ngyO5sLC6lAvems1YFr6zcKz0FOm17e/P5CYEPn0ChYkBfh5qtCscnw1uAkazE+eOk1U1EKv34+6id9yA7sWkQ1dNeyMfB2UOdBc1enCw1ToxZtLw96j0+J4tHgStZQ38+osMQWF1WhbOORWlKKIkHz7uLGY8fn2vSYdYrbmYte2uZsjR6/HjzE4oLq6u4Mdw5NBcyOkSXg+xADcB7d7DeyDnVzdNgtj+g9xxdPnG1ZCTnITzUG2ZBWJ/eYYLTPeU74Sc2+4YB7EUN5F7Y0Ul5KQPwOP+p088CLHd3JDpePt14nDhD0HOh9z5EARBEATBq8jiQxAEQRAEryKLD0EQBEEQvEqH1Xy0tjYSOdufH/kH82eY2d3xef6JAqzSeHjrQYhdEc8Nt1pa0eQpOTUUYltWfs7aYwYPgJwvPsXneaFQ6TAIcm6Y8GuIhemx2uk9N/FnxVt34HPH5oYmiGmDQ1hbF4LVd/eeOAGxXpFoZOWr5c9Rw9OxnzWVqBnwd6uQWGfBfprPoHHbiVKsVjk890rWrmo8DTkaHepOdIqb7VSU4DP07PRsiOUX8qrATVXY9xADXk6TbkTzuO1rtrB2QwUagx07gu95/fYdrN3agLqn1V9vh9gVV+Mz7Vy3Z/QmLdcOuXzQbKqzUFR2mnx92o9NcDC/lnU6TxVfcZzX1uG8EOPPr93kJJyHvsrDc3DiKB+L5pZWyAmLQ/PBZifXMlU14nYt+7Eyc35hMcQGD+TXTFYPrK5dV4vmXeZWPtaN/mikZfDH8RIVicZ/7voHhwO1KQf3o2lhds/urF15GjUffn44p737Ls7HjS47b1djzm9/dRfE/vUF14KdLEOjxk9XYkXecaOHsPY9d98IOfs2oVawbwZW5d68bStrH6tDjcUrz6Ox4T1XTWTthCzUmUV2wWvgwZkPQqwsn89XA9PbtZAtlma69dl/wTaekDsfgiAIgiB4FVl8CIIgCILgVWTxIQiCIAiCV5HFhyAIgiAIXqXDCk4zA1LIZGg3A+vbvSf7u1WLJkyxSTEQ89Njhb+9m/bzfblQxNU1GQ1X0sLcKlruPwo50x++A2IOEzeLMbvQeCo+Ng1imYloDnW4jIvgaivRRKf2GAoYP37lXdbueUV3yBnQawjEvnr+PYhpTNykLSEFhWWmRIw5zfw4mKw4/F587C2ImX3RSK3mBn4Me/XA46daUYBWWcUFpn4GO+SkxGGlW7Lw8bZz/RZIGXH9aIh1zUXxql8QF9mZm1EYm5KF46/reD4ejh4ohpzhA3tDzGxAcaxTx8dIQBi/TlweTNs6C8agYNKdazJm5GZag4b0cd+E1m/aBLEgE1ZTTgriommLB2NDqwNFgBkJPVjbWYtjurCoEGKGRi6WrfZQcTkrAceY2QcF35u3cLHiAA+VoAd3w+voRDUXtAbHYMVlmxnfs9mOJll9B3Dxc0ERClxze/aG2P7D/NhEhIdATlQUiijNq3Bur7ZxIzWnDufQxK74uaE/oGfthjq8Rvx98TOo9DTP27TlS8gxefgojjKhiNcvjPc9vgVfTx+kh9juan6fYfmuDZCz5xiOv5tvuBJiGj6UKSirfYw2NfkRPQubeETufAiCIAiC4FVk8SEIgiAIgleRxYcgCIIgCF5FFh+CIAiCIHiVDis4NWbryGhsd9ILDOfCmurT6AAZ1xsrK+rNKL5M1HMR177DWH2xJTQCYk7l5uxnREe4f723AmJ+AVyMdf/MFMi591F0vRs0uj/EmtyEXYtfQEFoxpQeEItM5C6kViuKwfZsQ2fBt7/cBbFwxStR3jXlCsgxalCUZrXzPqxcuRly7D5Y5TIqFKto+jbx4xCkQZdVuwNFd6WVvJpjkxXFmN1694SYvpiLRI/sRlfJrCHozhoQh33fsuo4a7da0J01JQfdDfUa7uo4ZgiOD+XE97PvcxSSmTRuIsJofp00t+J101noFZ9EBt/28dAti4soG1woMs7J6AKxutp6iFX48HHnbEGnzUGp3SDWLzGOtSsrsVJzTs5QiG3ayMXx9TYUuK48hvOX1opiyIwQfhxOn0HRfm3NYYiZ/PnYrzqNfQiNwGrUOjse54YqPm9HmFBAm5d/BGK+QXxfvSagIJs8FOB+7MnbIbb5S+563btrJuQkx4dALCWNu9lWVOK5r6togFh2Kt//gXysFOv04LpbU4nuy1P69WbthAg893FxKRBb9gWvkB4VhkLVowdQ+H6mG74fXSAXS3/4frurq8WOAt/zIXc+BEEQBEHwKrL4EARBEATBq8jiQxAEQRAEr9JhNR+m7AQKMLWbAyVn8eeo4XWoKQjUo7lK0VY0AtuwkT9T3LJ3N+SMCkGTmfT0ENauc6BuYvMerIQZ6MvNfJa8+RnkbD+Afbjy+uEQu+mGq1l7TC4+94/2RZ2B082MzN+IVXt79DBBrP+4BIgd28+fC9cFohnT0a+x2m5YENfRRAZiH4J7h0DMx4PhVVQY37a+Hp+/NthQt1DXyM+Z3gcfFPt4MJ2Ly+aGZTWF+LzcoFAnVF2GY+StxdxITaf3YHQ2oCvESnZyrciQrqhNcfri6xXsw2rPxSe4udOo67j5U4vlwp/ddjTyy8uYydjaPF4N2Oqh+nCEPgRi3VNRV9BYxzULcUFYodruYUx9sPpr1p4weTDk6PRo1JXiZqbVVIf7btTj9d6qx+shJonrMkwaNDrT+OK1dsJNJ2X3oCfxK0WtUVoGztGRSfw68gvDOaelFnUGm7bweXzfFqzA3XcQajcmXoNzaPdHed6OfbivGX99B2LWMn5+AiPQpI3seH7C9Pw7/m0jx0DO6YZ6iB06ilqtdzdtZO3kGNT3rTm0E2LDh4/k+z60F3Jyc1D3pLfgua6o4sdh+6b2a8LuwnnxfMidD0EQBEEQvIosPgRBEARB8Cqy+BAEQRAEwatc9OJj06ZNdPXVV1NcXBxpNBr65JNP2N+VUjR37lyKi4sjo9FII0eOpEOHDv1c/RUEoRMi84YgCOdy0YJTs9lMvXr1orvvvptuuOEG+PuCBQvopZdeokWLFlFWVhY9++yzNHbsWCosLKTAQBRGnY+g0BgKDGjPv33S79jf6yrQEOXW20ZBbJCHqqKrt37C2lot9qu8CE3MQtw8xnIHodin/4h+ENv9LRdf7tiMk2qQXzjEfFp1EDPquKg2/wQaVJlCsBpiXQMXcRUWnISc3oOw2ufvZ94PscpyLqo116AoyV5ZD7FWKxcqtWpQnNRoRmOwLtloHpeamcraVXU1kOPnh2K2IWP4Oas7idvpjTgeDD5cyDlqAlYAbqzAfYUF477mPf8Uaxce3A85UboQiBWc4edwY/EGyBk6CYWMdS1oaNXoqGdtd1Ox1p9ZcOqteYOIyMdO5HOOljIhigsfTzfj8dC6UHyps+L4vOmqsazdPSMFcv7+739BrKWJf8/zC0BTvF5XouAvKpFf34v+gSaGoQFxEPPzRSGss4mfU1sIGnwFRKJZWJObGDI4AHN8bVgZtqYWzciSu/G++pjw++/61VshVlvL8ywW7PvXi9dDzFVdCrGoJG4OueMwmnmVFqOA1o/4axYdPw45BgeOma3buEh0/Cj8nFqXtx1ip2vxMy4zhc+Few7nQY7Vg7mi5gg/P9dcNwhy0iPwhwOOsnqItVr5/hus7eJmx0UITi968TFhwgSaMGGCx78ppWjhwoX05JNP0vXXX09ERO+++y5FR0fT4sWL6YEHHrjYlxME4TJA5g1BEM7lZ9V8FBUVUXl5OY0bN64tZjAYaMSIEbRlyxaP21itVmpsbGT/BEH47+HHzBtEMncIQmfmZ118lJd/96giOpr//jk6Orrtb+7Mnz+fgoOD2/4lJib+nF0SBKGD82PmDSKZOwShM3NJfu2i0XCjFaUUxM4ye/ZsamhoaPtXUlJyKbokCEIH52LmDSKZOwShM/OzOpzGxHxXKa+8vJxiY9tFXpWVlfCt5iwGg4EMBhQP+daUkq+lXTA48QpeOXXdJnQETemaBbGuI3Ih1m3rPtZuKcMJ7tAOFGTu3MSrESZkolBw4LABEPvoow9ZW7m0kGMwoKjO0oTinReeeZ61U8LwPWf3TYNYQCgXqh7cg8fv23UoehowFB1UTxQVsPbYUaMhZ/K06yB2qox/OASHREJOSx26kioLVrrVBnFxVFNpMeRkdUGx8a05XPD24TurIGfBi29BLCycv97sJx+BnPpa/JZeXoQVOiPD+LUQl9MXcjZvRQdCXx/+XSGtFwpx4/qiK+djo2dDbNt6LupzuQnFWrxY1fbHzBtE5587UiNiWFXbrincpbdVg46yJw8WQCwlEEWhIW5ulVu2fgM5sckoAE2P5SJNZyP2odaD+Pmbzfya1ASgiLqqAR1BI/wxj5xuDp3RyZCSdxSr2lrsXIxb6MEd8/px6Np5/CjOMVrqztp+VhTHHyjC4xAQxI+p3YVzdoAeHVUP7kTH6fFhvGK0oREFmqZWFCCHmfjHpa8Rx4ePBsdjWEw8a59qxvNVasFHhsoXP55NxF8zvR86UJ88jSLb4lPc0fj1N5ZBzoM3TIRYhA6Pc1Qcn7d798tp+7/N3ko7VsMmHvlZ73ykpqZSTEwMrV7d/uo2m402btxIgwejCl8QBEHmDUH47+Oi73w0NzfTsWPttSKKioooLy+PwsLCKCkpiWbMmEHz5s2jzMxMyszMpHnz5pG/vz/ddtttP2vHBUHoPMi8IQjCuVz04mPXrl006pzfKc+cOZOIiKZOnUqLFi2ixx57jFpbW2n69OlUV1dHAwcOpFWrVl30b/UFQbh8kHlDEIRz0Sil0CHqF6SxsZGCg4Np9Z/fIpNf+3P2kyf4sztjBFadTR2AzzDR+oZIa+HPX/dvxWeTBw7gs9z6Cv7cP7UHqutPl+Fz/9JTxaxt0GGvfHVoCuSp8uyggVzjkR2fAjmRycEQC4vj77n6FD5X/fd7X0Gs5Ew9xJJSuSHapMlDIee0B6ObwaMGsrbyQS2HrQErexo8VIrUupkavfbqPyGntgp1C/c8eidr5+3Lh5yNq7Ei7xXZXJcRHILPhGO7YFXbqOgYiFW4VZR11OJ7XrMZK1MGBfLn+L0GoaZlwM1oYOQT4uHZdAs/fsrBDe0amxopqVsyNTQ0UJCHyq0dkbNzx5Vxj5GvT/uz96wQ3v8RHnRM9hp8Dl9bh3qBkERuUNVkxXO3Ov8gxEpPFrP2fZMnQU6YFqtyl1Tw6+joGexnsxkNsbLTUHdiMvLryNeEC7vSajRgc9i5Rs3Hg6FYiIc1YlwSmlZFh/O5qaUGq+/mn8Fra92Wb1m7Ry6aOdpacD4J0KIGo66Gz9GpXZIgp/AkVkO/qTufA1QMXu+ffLMZYpYWPkYGDxkIObsKUD948BBWtQ0xhLD2kAH4GTR48FiI/fnFv7O208Onvr8Lx9HCOagXC0rknyW/eqg9x+Gy0ZZTb1zQvCG1XQRBEARB8Cqy+BAEQRAEwavI4kMQBEEQBK8iiw9BEARBELzKz2oy9nNyKK+MjLpzDGjcRIeJsankzrHNaOgUEYtGVqeLuchQ74vqm5vvmAKxukpuDOQXhmKmV15B4VBYBBepPfTgrZCz6J+LIWb0QaHguNEjWLumEV0dtx9EE6DoKm50E6hDMVh8PApcI6OwgmVwCBc+Ht6DArtP1h6A2PKPv2TtF175E+TofVFsRg4UuDU1cXFU9+zekJPXiKKxz97iotprfnMV5Fw1GQ2TGk5yId5Hi/8NOVdMQbFnfFYKxIxBeaxdeRDFv4OHD4NYbt+ufLvqY5DTXIWCwUgP1So1Jn49OVq5qFCrRyO8TkOQiUjbPneUtfDqoAUnimCTK3r0hliDxQKxrdu4GLlvXxQPJkbg3NTQxOeOykoUWoYn4Fx142/Gs3Zh1RnIKTuKc0D5QTSaCnUz4QqKRIMvhxPfc22Nm6hWg99ZtR6GS9feWPXbYeOC2egInF/qG1C0nx3Phdt2D8Zqxafx2AT4o4i3T88U1g4ORNHw3NlTIbZlyQa+bz8UnO45jmZ1If48L28rCtqzk9Agrdwfz2uxmV/fH365C3LiUuIhNnREb9b+cv0myDG78Dj8/aOPIOZv5ELSyIh2ozO700J0CjbxiNz5EARBEATBq8jiQxAEQRAEryKLD0EQBEEQvIosPgRBEARB8CodVnAal2gkf0O74LLkZBn7+56DO2Cb+LRMiC1+70uIaVxcYJqYjC5x6V2xOm1MCq/8GZ2FArE/vTwXYn4+XKCZkIhC0o8/xyqD5SerIJZ/hLuxdr9mCOTcPBljys6FV2/86XXIOXIYxVID+/WEWKKbMK7sJDpBZsShw6Im3E2w64eCt7KKWoht/ALLJF43kVdg7NoNq/vu3YqiV6ebCWJSODqQ7tqKIi6HmQvxJk+ZADlvv46i4dRu6EJ62/28CvDx3cWQsy8fnVfPnOIVR3vl4HhvKsHqmFEJKbivo/xcnyri25lb0aG2sxBl8Ce9tv0a653FhboHjmPl1mOnV0IsPgor6hqDuUDyVPFpyGm2YzXq8GAuAmzForakidBBrMqfiyiThqCzc1Y3vEZ32dDtU9VxgXx4EjpQOqPRTTjEzTnUVoXCRF8N9n1HHh7noFDe/+J8/JFAQgDOxxEhfDuzB2fZGyagULz4FO6/exavBBsRjILskgMo5j5t53OAeTcKRyM9VBNutnBxsdaAwv4rcvEcVplRPF68n89pPiasavvZp99C7NpJ3PU0KhSPcUHxcYgdLMLPoP49+Gs6W9rFv07nhQvV5c6HIAiCIAheRRYfgiAIgiB4FVl8CIIgCILgVWTxIQiCIAiCV+mwglO7NYTs1C4ESuvJxYldPJQTr7agkPPAf9ChLS2eC2bueuwuyDl+Ckuaf/HRCdb+1XQsi/36W+9BbPy4K1m71a0sMhHRg0/9HmKbVqLw8Yprr2BtRxgKnJo0KFTSOrmQLLNbN8hpOINCucBwdPGrbeXuoicqUJTUqz8KTnMnchGvfzgKvSr2oHNhUCjuy8fAxXOtNnzPE65F4W1gMD9eH7y1HHLy9hZjH9zcIPvkoiBzy0oUQW/fiKK7Plfw8ddYi/s6WYwuj+E9Mlh71VdYvrusHpWMvfqiGHfcMF6SvHI3d1NssbbCNp2FcJuLDNp2p1xbXT37e20ruos6dCh+ri1Dh0ly2zYmOARSyl14HZltXOTuU4uuyt26oMulrZYL+ArLUBTYLToZt9Pge4ztycXVrSZ0E07th/sivVteFW73+b82QMxXj+6lZTX1rH2m3IOjcRi6rFbUciG6y+nhGDfWQywqCt/PkqVcwN6vN86FGgdeR/UV/JhekdEdcqLTcT4u9+X7KmvBa3vl9jUQKz6FYuZgDf+Ma/XBfvoTOkLHGUNYO9lDufu6QOy7UYf7umpkX9YuiGz/bGm1tdCXhbCJR+TOhyAIgiAIXkUWH4IgCIIgeBVZfAiCIAiC4FU6rOaj201pFBjQbizTeop3NW8TViwtOY3GML26oVHQgn8+w9oVJ7Aa4mtz1kFMuVVk/PptrJhoOYyahQ92ct1Jl+5Y9fLq24ZD7NobcyGm9efrRXMFmkqV7jsBsfrj/DmjwYCmQNfeMhRiplB8Nlicz6uCRgSg5qOmDDUDDSf4c1tbMm43fBKaux1ORlMepx8fD/7R2M/EHDSBC07kZkUWEx6H027PpYmI8nbksbbBB82Y7r/nRoiVVJRBzGjm7yemNxqd9T+BYyQrOY33SYPPe9MCcUwW7sdrJSiYj6OoMP583s+CmoTOQk56GvmfU7X58OmT7O/Z8aiBOVGGlYXPNOK1lZbO9QFNHs7v0BjUGWwr4X04o3Dc1Tah1mGcgWtRjCbUhbhcgRAz+GDMFMWvB189Vr5tPNMCsah4buil06EOLC6hC8Q27NoNsYYmft02VJ+EHLLi2Ovfqz9re/AFo32FhyBW3oSahQYXnytOVOF38MZqNE484FZRuNGG11+NFfVbBW6VpjUezBVVK87ZKQac07Q+XOvS3YTH/XYPnyWJifyYFn+KehKNBeeORmc9xE7kceM2pWk/p8px4UsKufMhCIIgCIJXkcWHIAiCIAheRRYfgiAIgiB4FVl8CIIgCILgVTqs4DQ8IoaCAttFUzfddi/7u7MZxT79BveC2MNPzYCYxp+LBV063Fd8EoocA6NDWNvd8IuI6HAVivvikqJYu8WGQrZjh1BwFBqFJj0txAWt1hqs7rj3W6zmmh3PDaqOH8NqjxHJKNAMCDZALKNnOmsXHkWhb5IGBW+n9nCDpII9WEU3IgUFdQlpGGtQbkY9VhzKVjsK1yzx/Nyn9EqBnF9H3QKxqS1cTOqjUMjmG4AVHfvq+0DMFMyNgvwsOZDzr+JVENtzhJ+za27GKp7HCtAYKz0jBWK7vslj7T7ZXOjbYuu8JmPVlSfIz7dd1Nclm4t31+5A8z6FRWBJb/dgRlbPr4euWemQ42xB4egNwwex9n+2bIecz9aj0dTJU7y6cVgXrGRsb8HON50sglh0PRd8XzEQjRoDTSiGLNrDxbh79qJx3tef4/uJCEPBpNHIjaycAThPHKtAMWSCm1B85DisKn26AY0Gzc14PYQG8u/cCfHYzzfyvoFYTAyfx3eXFEOO1QfngDBtMH99P5zXfdyqHhMRRQcFQyzAwceWny8KhM0uvHYtWq7Q1ZjR3C0uCivkNjajIZqT+LmoOl3R9n+r48LnDbnzIQiCIAiCV5HFhyAIgiAIXkUWH4IgCIIgeBVZfAiCIAiC4FU6rODU3ugkm6td1Ddz5qPs735adGOrbK2EWErXNIhZtFy0mdIlEXJ++4e7IBaW5ia+1GEV3Xm5f4KYcnPCqzyKIihf1I2SxoNgMtitKmtrM27Yq3dXiB3cycWdwUFoEah1oYjSXINOf+TLtx13DVb3LViHAjStlYs9/QiPX/UxdJu11dZDLCWNC7QaalF4lb8KhYXDnYNZOz07CXLqmvD1Got4rKGxCXKis9GpNDAGxWwBWi5Kc0SiuPm4uQJitiou/goKQXHgDXdfC7Ft67FC80k3wbHLbSZQHoqNdhbsTidpNeeMZTcR4B133ADbFORjtVi9FqfH+EQuyjtTjnPOju1Y3bjYTZxYb8OqrEY9CgxbzHz8tB5GMWulB4FmvAex57qvuHj1RAE6nD4w7RqI5eRwIf+iD9ZDjq8Br2VXPboAjxw8kLU/WrsJcrK64w8HSku4gPbf/8Jq1Gfq8Nj0zEBRbbeEcNbechCdUeNiUHzZWsnnJqsfutRW2XFe0Fu5cPmWq0dAzuK1X0GsqALdUpvdHFSTI9FNd8UKFMv+zx/uZO2RPXpDzv5iHMsGYzjE8tyE73pr++epzYnn4HzInQ9BEARBELyKLD4EQRAEQfAqsvgQBEEQBMGrdFjNx9vPvUV+unaNRdfe3dnf1x9ATcF19/wKYi4HGoiRk2spqmuwump4nAli5Uf4s9UWFxrKJHdDjUmrnusRQjLRWMdoxderK6+FmI+Drxf1/ngKo1KjIGY6xatHtjahRiLMhNUqq6qwSu/Cv/+FtYODsHKwxgf1Kj4ut2efN10POctfWQExXz88Xn947A+s/dY7L2IfnChciD/MjdQyc9AkKjQKj19VCX/Wmti1G+QYk7GfFjs+tzUY+XF2WvFZ69sfvwyxAOLPmPP3fAs5Qan4jLaXZiDE7HZ+/rvk8EqvzS1mon/CZp0Cv5hEMp5T1bahlY/F/V/hM/Err+wLsSB/1EUFBPJz3GJFTdSYq7Ey89KPtrG2rw41awEeKiWHa3nMbkWDwqzB3SF2tAh1ZYbgONYODMNxHpaG42fLnv2s3eLB1EzjxLmwS5ceEOudy/V1Ww7idvVlWCm4SwTXU8WHor7K4sB5vN6Gmrh1btV2UxNR9zUzdxDEivO5RuaEGU3Nvty3EWKxcdxU7FTFKcgpq8aqyiYDzif+/lwf5qcJgJzmGjTHa6rn42ZYb9TC1BHOlzt27YNYaxj/zBmY3D6uLHb8XDkfcudDEARBEASvIosPQRAEQRC8iiw+BEEQBEHwKhe1+Jg/fz7179+fAgMDKSoqiqZMmUKFhYUsRylFc+fOpbi4ODIajTRy5Eg6dAh/Ry0Iwn8PMncIgnAuFyU43bhxIz300EPUv39/cjgc9OSTT9K4ceMoPz+fTKbvBJMLFiygl156iRYtWkRZWVn07LPP0tixY6mwsJACA1FAcz4O7z9OOp92gV1EMhfajJwwBLYZMABFY04nGme5WrmIq6EaRUmtHipabvuKV4sN9yBMDApCw6iIbG74o0JRJKTq8VRoK1C8U7CFi7/KylDw1n/ccIjlDOMiOGcjmsF8tXErxOrteGyqW7ngrN6GlQ91GlzXhgZxU6yVa1AwGRCC1R0PFWIF3j89u4C1e3XtAjklx9A46mAe/zAbfhUeK+XhqojK5EK8QA8GXxHJWK3SpbAi77/+sYS1I/3xWI2+DcW4rXVc/BsUiqZUTuwWRXbFYzpAx993ZDy/Nhub0Czpp+DNuWPN3t2k82kXq6fEckFhUgKKFffkHYRYXBxey2kZXKAclYA5Og/nc8JYLvpdtWYL5OQmp0KsXyoXiWZdgeO8KgjniYy6OIj9+11u6GVuxLmjoRUF+ks/4vNCoEKBea/+KFRNzcLrITSTixrn/+U+yPnwZZwXSkt5X2tbcH4e1B9F4Ou+wX2FuAltj5zCCsD9RqMQ/bjbfDLt+qsg54Y78XOJ3EwmKypwTj18CsWytnoUF4+axPdvqcV99czA8V1fz8WyZUfQzLHkBJrVBZlwfOf25p8lmpr2HzNoFP7Q4Hxc1OJj5cqVrP3OO+9QVFQU7d69m4YPH05KKVq4cCE9+eSTdP31302e7777LkVHR9PixYvpgQceuJiXEwThMkHmDkEQzuUnaT4aGr77JhYW9t0Kt6ioiMrLy2ncuHFtOQaDgUaMGEFbtuBKn4jIarVSY2Mj+ycIwuWNzB2C8N/Nj158KKVo5syZNHToUOrR47vfc5eXf3f7PTqa35aLjo5u+5s78+fPp+Dg4LZ/iYlYZ0UQhMsHmTsEQfjRi4+HH36Y9u/fT//5z3/gbxoN11QopSB2ltmzZ1NDQ0Pbv5ISNMcRBOHyQeYOQRB+lMPpb3/7W/rss89o06ZNlJDQXv0vJuY7oUt5eTnFxrYL7SorK+EbzVkMBgMZDAaIx2Qlk+Ech9MJt1/H/h4ejUKY3d9iFVOXA6tHRkdyQY5OYXXCxmp0ndS4GcClenhPJXkHIBaXPZK1bS50kmuqQ7e80x6ElvZqLi5rLsX3t2szHoeJt4xn7VoP76/biJ4QM4SFQCy6Nxcwjhs5DHKqTmDFzIYaLnJ96/+WQE51Dbq6+vqjaDg6lTvCDh2HLp7VXbC6b005P85zH34ecgIicTzMmDWdta0eqpIeWp8HsdMlKNw8tIlXGG6oRHfDmHR0IIxP5ZU27VoULvtq8JJuIRQkRqXzapiN5VyA1tyM7+/nwBtzR1hUNOm17crb2AT+Xo+fOAbblJYfhVhGJgpAW+y8eqvRhAsjf9RZ0sAhbgLGplbIKT+MzpcFip+Hb45jxdxHX5gJsTAPYsXrRnDHUXMtXld7NqGjZfcU7qBafRIdSCffgELYlD7oHLp5Gxf2lhwqhBxbKx6bVh2/JrcWFkBOeBi6RCeb8GS0Wrm7bJMenWzrPQgnb/7TzazdWITHwVGH19q/31vL2ju34rzub8Jx/PTvfwMxbSQfb3+auxhyio5HQuzh+25k7S8P4o8LIoJQHB/gQmGvyZfHxt3YXqW3ubWJ5q6BTTxyUXc+lFL08MMP07Jly2jdunWUmsovztTUVIqJiaHVq1e3xWw2G23cuJEGDx7svjtBEP5LkLlDEIRzuag7Hw899BAtXryYPv30UwoMDGx7FhscHExGo5E0Gg3NmDGD5s2bR5mZmZSZmUnz5s0jf39/uu222y7JGxAEoeMjc4cgCOdyUYuP1157jYiIRo4cyeLvvPMO3XXXXURE9Nhjj1FraytNnz6d6urqaODAgbRq1aqL+p2+IAiXFzJ3CIJwLhe1+FAXYCCi0Who7ty5NHfu3B/bJ0EQLjNk7hAE4Vx+lODUG9x0/40UYGoX1CUkcpHo2mUbYJu1X26C2KPPPAyxomOHWTvag6smOVBIVnKGC8Lqq05CjiEYhUNZg3NZ2+jB4dRVi8KeE/loLZ0Sk8baDXUolAv1CcF+BXLBVoRfEOaEodDSx4giroiIXqzt50RxYmIa9qHFh7v4rd61GnLu/NUdEPvtQwsg5hfIxXJWG5b5zh6M7/HjNz9j7XoPTq8llfjTTo2RC5xPHz4BOQufeRNi8dEJEKu1cLfGFguK1E4cPQyxnfv5ePhmBYrGbrkVHVvH3jkWYhpfPr6L9nF3Q3OLGbbpLPg5nKRX7eOjpoyfT2MA3kmZdN2NECv1IKwsKeKC6Ih4vN57jewDsWZnPWvHJ6O4j1rw+mvV8mur9jSel2efxHF3003ovql3E69WN+PYd9nQ4VQ18bwBw9BJtOugNIh9snIVxBbM4WrE2FAU9fZMRIGx3cEXr3YzOnuWFKPIPTUCXahPnOZie58gPeQ88ac3IBbdlc/bf5v/GOREhqNYVhsawdp2Hc4vdS0oTD9QUAyxfV/wHzS4dDjHfbsjD2K3T57I2q1aHGu3ThoBsS83LYVYsNtLfrbxm7b/W2w4l50PKSwnCIIgCIJXkcWHIAiCIAheRRYfgiAIgiB4lQ6r+YhJDKLAgPZnbHa3ip57Vu2FbepO4HOzHWs2QmzI1dwUy1qPZjs+rWg8Y9TzKqIaJz5/jQlPhthbf+VOjoc9PM+/9+ZrIJaSiM9R12/cxtqeDJiGjhsFsaMnuEYhIgx1J4H+qO9wuXCIVBRx7UZDKR53Y2+schkRHcLa2/fhuVnzyVqIvf/eBxC767dTWTsgDp/b1tejedf4G7nRUlocnueEODzuS97mZj67tuVDTpw/2ntrbThG7rmPG745NEbIGXBlP4it/YprPmpK8fgVfIvVWQeO7g6xgGj+mrUnK1jbkw6ls9AzOZaMuvbz2mjlpn4BcagDqKqrgJjLhfoHaxM37woLRyMtvxDcLjSYv2bZNjTXculQt3S6jusTSmvxvLSeQf2D46uVELtm0kjWDo7Ea/v4IdSQaRUfw8u+QqOzMh80SUyJT4FYbAjXeDRZ8fW2FWCF175J/JrsGYdVewNMOH+ZYlDfMziT6wdLa/EarW/Fc9EliRuWtdajUaM+HufVcddwzd+GDWgCaXXg6yUmpUDs4CGuF2lqwUq0IWFowLllwwbWbm7FOdvloZL7H+f/AWL33j2XtUua23VPDhfqiM6H3PkQBEEQBMGryOJDEARBEASvIosPQRAEQRC8iiw+BEEQBEHwKh1WcGqMMpJ/ULtoTKfjYs+IJBQXxUYNgNjO9VhB8FgpN6P5zf/cBzlVgejIOP7mkaxdkoeiw7RsrAz72YZ1rK2zoRHN0aNYadPPiGKppkYuZjtxBsWr/Y+jiU3hXi7QVQpN1LoO6wWxzEFZEPN1MyM7srUIclKMKDz6/DPeh965WHX2/X/8E2KxmSjidRE/Dj4KzZ5cHqpjWqr4+97+Lfa9OgtFfUFuAt1GO4rU7n9iKsQqjmL1zZcXcPOlrHQUzyWFYmXKwVlc0Fo8yUMVYoMWYmve3gOxjFQuEExK5sevuQVF2J0FjdZAGm37+4kO4deyzYyCxt5JKBzNq8XrO70rH4tGHxQ6a2pRdFgb4CZCdaLgr6cH865Ff+fiTr9WnJdMTryWA5vR3M5QwgWF2/PQJNFlwH0tc5u/giJ7QM6mT/EHALrBWJn5mnF8jvn3p1jJNzIwAmJOVc/azRo8xsHnVDI+S89eGRDbX83Pa1Ep9uGeyfgen1y0jLU/37QZcn738BSIDb+SC05X/Xsu5BwsOQOxkt14fn49lH/Ghe/FuUPfiCJeXwd3BkuMwM+WBp8GiJ2uRVFtcT03SdS0hrT93+W68GrYcudDEARBEASvIosPQRAEQRC8iiw+BEEQBEHwKrL4EARBEATBq3RcwSkZyUjtgtOTB7kwsFsPdG2sLq3G2CGsdHhyD3cE1HoQjSUkoeDP7MfFfFZrDORUNGIf4pO56MnoQlFXdloXiB07iSLUkWOHsPaatRsgZ/EbKNrs3ZULqBxWDyXOm9Flz1zXCLHI0BDWDo0MgZzN3+6G2LY93H0z7yhW7Y2NwSqX115zLcSCgrhgqqUGRaKWU+g0GR/H3f98tChKtSmMpWRmsvboq7Bq6KAhQyD23LrPIVZr44LHkGh0g21uwnNRV8urrI6ZPBByImJRaDh72nMQ++KrDaz92qKnWbvRjG6HnYUgHz35n3NN21v4+YyMwONdVIDXWo8uKFaMieLjx0Z4fZwoQJfZpDh+fYcloMuqMxTHsH8gF1HarShUTYhEgWZEAAqP/YO5aD89FiuitjSjYHDWrbzSdL4HR+P0PjgXJmdg5d533/6Kte12FDabgtF1OL0nf48JEehCXHEChfZrNm2B2NtffcraLi2Oh9JCHP/mZj6OwoPQXfqtF7EK7MIX32Ltx38zHXI+XIPi1fw8FPFmxqez9h/uQZH75//G8ddnIBf3R+dgJXetP577tRuxcrbVwufVuOj242J3WonQWNojcudDEARBEASvIosPQRAEQRC8iiw+BEEQBEHwKh1W83H8m3wKOKfKakkRf959RX+s+lnowfhp2v13QeyrddtZ+8N/Loec26ahzsDpJpOIzkYDrntvewhidjM35RqUhWZCxcfQ7KrZQ5XBHjG8suK0h/CZ384t2yCmt/NTXZiP5lfHy7APo60jIZaSwM2uDD5o7nP9pCkQ+3ZvMWsnZeBzx9J8NNapO1EGsWPbufnS6WI0jtLVY7XYmhiut4lPwkq0Oh2uyS1VXCf09bIvISc5Bo2P/jDrUYhddzt/Zp4QiZqjPWux6umRQ/tZe/iE3pDj68AKp6nJqF+qKueakvxd/DmxubXzVrX19bWTr2/7c+msbH69ffLVKvdNKCgKNQuHCnAslpZxTVdSCj73P1WJFV5jEvk5byzHazt/Gz6rH9arD2uv+3wD5PTuh/oHTSPuv+QwN9Nauht1Lj7Nnip18/E59vaxkJM6AK+jPR40XSv38krMAfowyEn0cP2NHzuOtf/8/EuQY0aPLNKG4zXp51ZZ11qF2rBBuVdCrKCeVz4ONqDWxm7Hvtt9+Tz05Zeo5ahowOPucquiTkRUWMfztn2zAXJSM1MgFtuNj9MvNq+DnOUfrYBY7554HEw6ruWxnjNmHK4Lv58hdz4EQRAEQfAqsvgQBEEQBMGryOJDEARBEASvIosPQRAEQRC8SocVnNacriKLX7uQJc1dGKhFkVDOIKzKWl2NhjgP/I5XsX3l769CzpF9KDbT+fLDZa5Fg6FBw4ZCLC2WC8Ksp9H4zElobHXTHTdhnoaLV8kfBYYTMiZCzFzOBYRJ3VAsq/RoPJacjVUTa8u5i0xYBAoaT5WhYHL641wcGxzlQaB52/9ALDEOhanRUW6mQ7EpkKOpR7MiSxg/ztm5gyCn5ChWhdy4ZhNray14vlxWrOSr/FCMGx7L1/xNtfWQExOLQry0BG5i5uPBHG//5mKIXT8RDdFamrlAd9cGLkButeN76Sy4dDZy6duv1b2HuVA3Ig7FkUdKsarooEE4No4c4qLQ2sYT2AFf/E73wbtcaHnjrddAjjkAp+PXF69h7SoPgr6N+7Gy9aBMNC0sa+Ui49jYdMhRHsZi/578+judh5XCk1LxWhvVNxdiVw4Yztr5B45DzsAuKMg/WsjFsg21aIhls6PAvKoM52idhs9z4wZjPzdsQHNA5WYO2VyDCteBOTkQ+2g731ekDoWkGTE4z5rPoGma8uHn3xSOY9nTufho1VrWXvb1LsgJ06FwOSwgBGJxkfx9J8S2G35a7S20AYsEe0TufAiCIAiC4FVk8SEIgiAIgleRxYcgCIIgCF5FFh+CIAiCIHiVDis4bbDZyO7T3r2cTC7IyS/Mg22i41GYGBwbCjGnjgtmfv3onZCzY90eiI0ewV1Vg/1RMGkKRbFPQDiPJQRg5dYu3VIgRv54emqq61nb4Iciq7AYdN7btI8LjlLSUFyUnIriJb3RBTFft34dy0Nxbky3ZIhFduVVQn39sHLre58shti7f3sfYhG9+HusPI0i0ZI8dGztfW1f1s5ITIGc+Aw8fv2tvVn7ZMVpzBmBAkXlwOqiZUVc3BjUguJpcyWWhvQN4mLj2gYUU69cge62PgrFoz1y+BgsruDXhNWBgr7OQmJyEpkM7dfm0WPcIdfHFOi+CWkrKyFWfArHVHw8n0+OFaJT8NCRIyC2u4Cr8BYvQTfJP8y5GWLHGrhb6rKP0QW1phndaH0MKEb2cZvuM8JQNJ3eB8WeJgMXWhYWoIPr3q9RYK4JQRFv6VE+rmM8CCY/3LQRYio/hLWTElFQG6hFIefuE+jianPw/mflpEDOmgMbIKYlA2sHm9AVt6YSnZb9g3i/amrqIQfss4loxp13QGzzDv65FJqCnzf7T6Di86MveDXhVhdulxHtYc6ORMH8Bjc35EZb+zl1OC983pA7H4IgCIIgeBVZfAiCIAiC4FVk8SEIgiAIgleRxYcgCIIgCF6lwwpOl366mnTadoFdeBx30ezWFd1M9UFBEKuqq4BYeCgXDjWeLIEcX6sTYqVF3M3QPzAEcv7x2v9BLCaQC2EfuOEWyDlVgf0cfM1oiH2zditrFx/D7Xr0RefCqgouujvhgyJRjS+KI9N7JGG/+vdm7fhkFPqSh31VlXCxWWwSnq/ySnw/q9zcRYmINAYuVk2KQfHX/h37IGaz8O2CrkLhVcmZMogFhIaw9tPznoKcejMK8ZpK8P20HOX797WhqLemFJ0Z/XumsHbXvrGQU/mv9zBWjuW6naH8OAy7k7s8trS20Mt8qHUafI060vm1zx1aI/+OVVaBzpE2JzoFa3x1EKus5sLcgGB09928FcXqkW4OzT4OFPKRCwXEt9/C54CGIhQnG+pQUFx6Ep1XkxMSWLvMhqLmtAEoOkzqw7crbsXj52jC+dJox4+XEH8uvjS34HatPgaIWRr4eD1cvh9yenVDsWyzBa/J+Fg+79Q1VUOOXosOw3YbvyZtCgXz5I9C38Yz/JyZPDicVjSh+PfzNWsglpPD32PfYTg/b9mKx8bfyH+wodfimLHbsA9lpc0Qs7mJVUtr28eD04XX0fmQOx+CIAiCIHgVWXwIgiAIguBVLmrx8dprr1FOTg4FBQVRUFAQDRo0iL76qv33w0opmjt3LsXFxZHRaKSRI0fSoUOHfvZOC4LQuZC5QxCEc7kozUdCQgI999xzlJHxnVnUu+++S9deey3t3buXunfvTgsWLKCXXnqJFi1aRFlZWfTss8/S2LFjqbCwkAID0djn+6hvqCZfbXv3kqP4c8cjuw7ANoePoOFPQibqH3x7dGft1tP4rKtmP1ZuPLLtW9bu3X8A5Mx/ci7EyIc/O3ZW4XPIb3fvgFh4RgrE7G5dzd+F5j65HirWBvnw53SWFlx35u3Hyb44H42Wct2qTuoMOIwKdmClzSNHubamay5qRdKyUctz1XVXQsxirmftmjI8pj27YoXJhBh+bL74cBXkhIejyViLvZi1QzyYyVU2oKlSpB73panhz1ELS3A7lw41M8mGTNY+XYfP3l987UmIFR3BvD5Dh7G207eetRsbm4gegc1+NN6cO1x2G7m07WZHA/ryMVW99lv3TcjoYQxXVaAWwNrEn5XHeqhGGuWhCvORk/w5fJQBzQ/9I0MgVmnnGpOkWBx35Y2oFXGE4jGrdvBrPiIQjQathCZRrQa+/8QuqDM4vBHny1oPla3vnjyStQ8U4Jxd6qFa7HE3vVhqJvb9eB1q90wm1GBcNYZXh66rr4ccn3rUc/i76Q4rG1Az86srsaK4Np1rug5vQj2O3Rc1QCeq0PjOVVjM2mNaukNOc7MGYuTkZpRNjfWQojFgHyweNDlZ2VwXdMutE9r+39LaTLc+gkaRnrioOx9XX301TZw4kbKysigrK4v+/Oc/U0BAAG3bto2UUrRw4UJ68skn6frrr6cePXrQu+++Sy0tLbR48YV1RhCEyxOZOwRBOJcfrflwOp20ZMkSMpvNNGjQICoqKqLy8nIaN25cW47BYKARI0bQli1bzrsfq9VKjY2N7J8gCJcvMncIgnDRi48DBw5QQEAAGQwGmjZtGi1fvpy6detG5eXf3dqNjo5m+dHR0W1/88T8+fMpODi47V9iInr9C4LQ+ZG5QxCEs1z04qNLly6Ul5dH27ZtowcffJCmTp1K+fn5bX/XaPjzJqUUxM5l9uzZ1NDQ0PavpASf2wmC0PmRuUMQhLNctMmYXq9vE43169ePdu7cSS+//DI9/vjjRERUXl5OsbHt5keVlZXwjeZcDAYDGQxoKnP/o78if2O7uCoyhgtmivJRDHbDdaMg1qhBEc3q5etZ21yGlQgHdk2BWHQQF5iW1qEZVWIXNB3yDzGxdnA/3Hd6bxQmZvTqC7HSQl6xMK23B9FmX/wGGBXBRXdrPt0MOYGBWKU3NBir5pKer1ltGqyqqbOicZbJzs9FejyKxqKzUMDXZSQKaEsOH2ftPul9IGff5p0QcyRyIdnEwShm3f4Vumt1TeQiO3sziuJiYrHvtmqsVllXz0V9sRkois7IRZMjpz8/FyfPoAGQyYM5Xk427n/Og1yYerK8nrVtjgs3C7pQvDV3tJTXk0bfbuxUvJ9XNx7YrQds06Mr7r+4BK/vyjIuAvQz4vHWG9DAaUAqFwubbHh+d25EU7w+43hfA+x4XhJCcO44VIkCbB8XF75Hh6H5XEYWXpOtio/hVRuLIafxBI7zVjPOq33H8DnmnmvGQs47b6IIPMgvhLUrbNj3pnI09BuU1hNiTrfK4N/uxNcbO24yxFbt4qLhrl2wOnliFC6Wh4Xyc31DD/yhwgtvfgyxoGA0EQw2cDPFafe9CDnZCbkQ0xv4nB0bgGZyBj2Kc4eOxjlt5DX8c/ZMWftncXMLjoPz8ZN9PpRSZLVaKTU1lWJiYmj16tVtf7PZbLRx40YaPHjwT30ZQRAuM2TuEIT/Xi7qzscTTzxBEyZMoMTERGpqaqIlS5bQhg0baOXKlaTRaGjGjBk0b948yszMpMzMTJo3bx75+/vTbbfddqn6LwhCJ0DmDkEQzuWiFh8VFRV055130pkzZyg4OJhycnJo5cqVNHbsd7fOHnvsMWptbaXp06dTXV0dDRw4kFatWnXRv9MXBOHyQuYOQRDO5aIWH2+99db3/l2j0dDcuXNp7ty5P6VPgiBcZsjcIQjCuXTYqrb9ElIp0NQu1Px6MRdIBpiiYJsvlu2C2OEjxyGWncmFPKk56Nh3ogSFZImZXJCT3QdFjvWt6DZYdoQLr3adQCFW9yFdIFZ1shRix4/xnx5O/fXVuN1x3K7s0GnWHj4RRU83PTIGYj6tKCAyN3PhWnUDikvjMlEomDDYzVk2EMVzJaWnIfb+whUQKzjMHW4nX4OugbffcgPEgpJ4RUnLCXQyDDeh0KumlXtIRAejYMtkRBHhwSPophkUxceRfzi6VtY3oNPkjhX8GqgrQaHvQSOKHbt0RxfEqmIunAz25efC5sTqqZ2F0tIyMuraxbkqiLuJbi9A116rFcdiVJQHd9pAfu527kcXz4gQHD/RbtslJKODbdFWFDHHabkA9PhxdL202lAo2OKhSqommF+3K3aegpy4ftj3XrnZrO2owyrTJ6pR7HmmGue5slffZe0Z026CnNU7Uehrs/HrobUVBbV2O14PW8rQQdVSzNs1HiryHlz3LsQ+fOVp1i4qw7n+9wv+CjHVGMLaN47Bc/PQtddCbP2O9RA7VlnM2n2iroCc8BD84UBmGO9DSjyObbO+FmLjbscfcbz3789Ye/WSb9r+b3fivHU+pLCcIAiCIAheRRYfgiAIgiB4FVl8CIIgCILgVTqs5uPInhNk8mt/brtm5Vr290wPZjjBAfh2bhiFJlJGt4KSWnxERi0ufF5p13N9gMWCJk8O97KzRNSjB9dzFOzFZ87FR9GdsbIBjdR0bs/iK0/h88qq0nqI+fhw8xtzDT7TL6zC6qoNFfhcs9HMn02Pvh6fO7pCgiDmq+c6HYMvGvLUnUY77b++8gTEPlz+H9YeeAVWww33YGJmcfJztvvAdsghLeom+gzi+p6ErmjctXUN1iGxm1EzU1jAn2lrtPgcPzAMt/O1c5OxulJ8zu6KwGugtAzPq5+J60zGX3UVa7dYWujN3Wh81Blw2fXkonYdhL8+hP396Oli2CbU03j1sO8QEzc1u+G6qyDn+HG8lsPd969HnVR9FY674ko+Dx2vwjnBYkX9iFI6iPmF8Ilv1BWo+1r07mqI1b/5IWv/z6wHICfuGGqu3npjHcRamvi4KzqKY3/YSDS2WruG6/mcLpz3mltQbxBgQk2X3s0kUavF7fy1ODcpHR8RW7bvhZz6RhxHRi0/10dKsRruTXeg1ubvH+MxrTLz8Wcz4jjq268fxrpxQzSD1oOWj1AHkvftbohtXcv1dmZL+y/SHC4cd+dD7nwIgiAIguBVZPEhCIIgCIJXkcWHIAiCIAheRRYfgiAIgiB4lQ4rOE3L6UqB/u1K0H713EDmwF40FItsQLOdrrGZELNZuJgoZRCaMAWhJojWruWGQqfOoFiKFBrduOtZ46KwGuLxQhSpjRs/EmI+jTtYOz4RBT4mXQLEli/n4q+PV6IY7LeP3Q8xm4fqrdHBvHJv4Z6TkJMxASuH+rgNt5Z6FLNa6lDEu+0bNOpKDOMmZn269oacgx6EvSFxXBA2YDhWgHRa8By63AS7Fiv2M7ELVhh2eagI7xfFzci2f4HvLzcRx21B/hHWTu+KglqrE/ve2IR9tbfwY196hB+rVhuKHzsLfoYAMurahY2FhVy45x8SAttUVuAFr1pwfMbEhvMcK1ZX1WjQsKzBzPM0ZhRMEmEFbh8tn9MCo9FcsboQjflMPigo1zRyEylfJ5riFZWioPWMlR+HZ/6yEHLmPfsIxJxvo5Cz1szN+mxOvEBuHjUcYk2Hed99tOGQ46PDudDhwfRq8KBBrP3Oon9DzsCBgyBmb+Tn7N770Bjs0FF08rU0uxmkOVHs+fUmNG4bOwHFzB8v55W6TQYcM1UlOB5O6Ph4OHkac4KC8ZhGRsZATOc2RKL92z8P7E78wcX5kDsfgiAIgiB4FVl8CIIgCILgVWTxIQiCIAiCV5HFhyAIgiAIXqXDCk4DUgIoMKBdqjk5YST7+3VTUYxTsAaFe5ZqFJK5fN2qsjahU2RktAli+Ue5cCjEQ2XAkVei22dqXCBr19fXQ05AaDDEHC0oHhw5fiBrO/1R3BYehu6b9i+4wNTuwRkvOg6rq5pd6NjXUMn7dfoUitTsOhxaaemJrF1Th4LdM4VYkXf/liMQa2rgIrheyVgV2KcV++Xj5PLfsNBAyGlpRuHakSLuEhqRjMclLNMIsZheiRBzabhIzMeMgtAhE1HwNmDKCNbe9NVmyKk6jG6m6UlYgffqibxaZVocF/A2t7YQcRPZToOvyZd8zxl/ycG8avXBIhR3Wx0oTAwPRtfJ6lPcgbdLLxSAhvjh2Kh0c9/UOPH6K8xHgXR9M3fo7JKWDTn2JhS9xhtxLPpbeR9OHSvG7SJwHqo/7TYPNeH7O1WA485Hh6LXltZ61l62Yg3kjB+P1/KE67gI9W+vL4Gc4hK83mPjUXx/tIKLLZu12M/3Vi6FWP+R97J2TVER5Nx9LwrYP/gnr6x7pgQrrRfm4X2AB2ZOgdgpN3fkIC3Os0P794bY6o3cfbnehq8X1oKfJUkhuP8pQ/qz9onKdjGwxW6gj7GQsEfkzocgCIIgCF5FFh+CIAiCIHgVWXwIgiAIguBVOqzmY8eXu8jk165BsPvwdVKwPxqivP3mRxC7b/odEOs7ij9PP3biFOS0WNAs5d4/387aDg96CJcTn5tptPyZaagVtRU2D9VP9Wbc/4oVvOrkgb15kHPzrZMg9uRzv2dtbagBcvwNaNKWV3kQYl+tWs7atc34vDciBbUUxgBuKNTbg5HPFx+g+ZnehVU706O4RqGmogxyUvtGQ8zpz59pN3qoTGyz4vN4snMdSFU5mq8Fx+Mx1QXjs3eNLx/L8fFo5FPXgP0yhHEd0pWTx0POZ1WfQiwqFnUJ/a7gxnpHTnBdjcXQeb+XNDkt5Dhnvqi3csM0jR7HU9fUrhCLC0b9g2rmWiMfD2Ol3ENl5uIGbpLlakWNydAhwyCWV8Cvv+hUrPiamZkEsd5JmKdt4AZfp8pxjkvpgholXQuv/NwlE48V1eE4b6lGzZrWL4S1Nb44T1R4MHdL6JHC2mm9MiCnuBbfzxkPlYKTkvlnh9aIlW+Dw/D9/O1vX7J2SUMx5LTa6yFmsnEzwOH98fiNGI4VhnUKx8iQvnyu6N6tJ+ScLMDPM4Mv/8wJ8g+BnAYPVdRPlR6D2LDhXHeYv6ldw2JRYjImCIIgCEIHRRYfgiAIgiB4FVl8CIIgCILgVWTxIQiCIAiCV+mwgtPiE5Vk1LebMXXr0Y39/Y3X34dtWhxY4a/GheurPTu5uG7/jkLIiQoKhVj2JC5Msnmo4OfSYpVGH+JCTh8f7KfOB0VPxw6fgNgXyzewdmQcClV9NVgx89ihQ6ydOx7N0Hz98Vj1HoqmOS+/8A5rW6243dBbxkBMo+Gizd2HUMz00WdoOjQoA42CrhwxmbVLzqBRnKEJRckx8VxsqHe41xwmMgbgMa08w0WE5goUddVWo1lRz9z+mNdQz9qWOny9j5ejw9fO/dwo6OG7H4Ccwjx0+Kk3o5lbv1uGsLafnosWHc0oeO0smCJiyF/fLs7dvokft6SMLNimtAzN7fzsaN6VkMyNx06fQcMynQdBa/c0fnx7dcWqz/U19RAzafm1Fe6Pc0eTA4XOkaE4fzWbuQDU5kEwGWjDa+aO0dzgq8qOgtqhuVip+7rh4yB27CQXk4YnoeD0pRfQ4KvfQD7/z5p5L+RUFj8NsdPHayHWK5GLcYeNRIH+nr1oBLZs3XrWrjfjXB8WkAMxA/FxFBKA5nW7DnwDMYsVhalpabzatcWF4lyNh4rGysb7EGzEisbVDXUQozSsnP3uCv6jgMLa9rnC7rzwathy50MQBEEQBK8iiw9BEARBELyKLD4EQRAEQfAqsvgQBEEQBMGrdFjB6U0PT6GggHYxUnMNr0Q4wT4YttGFRkJs3NUjIHZsM3cNDPZD4ZDWiIK7liIu2tHo0YEu1EOl25YmLig8nodVWn2sjRALMaETqq+eu9Dd9fvfQ87eNdsglpjoJrKz4ql3mlBgZ4pDgVtwEu9XvwFjIUerxarAdjsX6K5zE3AREfn647kYc+tEiDksPO+fb3wIOdn5KP6a/6//Ze3aM3jcA/R43FOTuLNgXR0K2YJDUBj70RvLIfbt17z6sqMRXXEbWnBsGVxcsBsShC6M0ano6jr6WrwGtFo+JitO83FlbsGx0FkoOVNFfrr2/sfFcbGn04rHOzYej5t/ADr+2ogft6pGFOk12ND1tKaCuwDbLSgw1zhwu4wUt0rQp09CTv++6HLZUov9aqqtZ+0gXxTGRpqwonNtfRVr7y/F+St0H869N09Gx9bVG/az9oebVkFOgwWdUYtruAD0ymsHQs5fX5sNsZJjWNX8UzdR+6w/o1C11Y7fyzNSeEXhZg9C+57p6BCbGMTnqpQ4/IxYu207xEqKULw5ws0INcxD1VlzDc5pPbP5/L91ez7kpMXh/JWVjRWGl67jfVVB7QJah/PClxRy50MQBEEQBK8iiw9BEARBELyKLD4EQRAEQfAqsvgQBEEQBMGrdFjB6YmjFRTg3y76zMzmZcGvueMW2MYVjG55VhuKb4xhvFR2TBcU2gyZgg6g78z6F2undI2HHD8PpZjXrd3D2uUnsE/du2FZ9ZvvmQKxCddfx9p/9eAG2FJaBLG7b+fvsawYS9BH+qMQqsmCwrUX3nqGtfX+KI6sOYRCL0MgF/HecxuWhO/fB90ne6WkQGzjR9y1MiECHRZjjejyaKnhfag5hcLi1xa9C7GwQC4+vPm+2yFn6u3TIdZUheLGlFDucNhgRnfWwYNGQsxFXBQa3xfdB6/PzYaYLgRCVHOSCxeN1VwA6WxFQWRnodXSSuock98APy5+LjiKgslWazDEmjwITrum8HHmFxwCOTFG3FfBvr2sfWrfAciJj0DXyTjFxZfXTUHXUH8Ps/iJU+jQWXiEuxxH+aE4ssaBbri2UD53FJShKNW+Gd2KI8cGQcxoaOD7dqK7r58eXYcdbgLdh+/5C+QE+OLxCw3BOc2p49dkdYsHV04jfi/XtXLn0Idvmwo5E8aiK+n6j92E9RZ0xR3c52qIOXyqIHbgAB83g3r2gZyYCHRQranmAvmICDw3AYH4I4H8g3hexw7hYt9DR9rdnm1orn1e5M6HIAiCIAheRRYfgiAIgiB4lZ+0+Jg/fz5pNBqaMWNGW0wpRXPnzqW4uDgyGo00cuRIOuRW1EwQhP9eZN4QBOFHaz527txJb7zxBuXkcCOnBQsW0EsvvUSLFi2irKwsevbZZ2ns2LFUWFhIgYGoyTgfR3cfIH9Du34ip/cd7O/KD59JN9mrIRasxef+W/bw593HClEjUWHBaoFfr9nA2oEFaEb1kpsegogoM5dXIiw8jM/RMrqkQKyuEc12unblzzCrmuMgp9/vsErjgLGDWNvsQC2CpRpjjSexgmV0Nn9NsxWrKO5cigZiZn/+fLfPOHw+OqRvX4jlb9gLscGDurN2VGoU5HQdhvoHjS/vwxvPLoIcKz5qJXs6N2QqOIK6gZpSPFa53dGk588LuDbk8LEGyHnhj3+D2POvP8Xa4clYgXT1e1gdMzIGr4Eeffnz/t3bdrB2q+3Cq1NeDJd63iAistfVkY9ve/+TM/h47du1H2xT1YhzR+8+mRALD+Xf14pKsfK03YzmXeN78dfcko8Lq+AoPJ+BEVxDtqdgF+T0iMM5oPU0muBFGriuLCQEj6vFhnqOoip+bOy+ODZiErEPeg1qX9KTuE7pz3PQIG3xuxsg1ljP5+PKCrxIrYFYZfxoKR5nrR8/P4EeKrzGRqEeZs79d7N2ZG+sJqxxYR+iI7kBW/4R7HtKVzT10znw4zkijc97KhxFFkl9UPNxcg2v2lzX4sHkTod9z0jGMRKdyMdRY3P7/GW164kOum/hmR9156O5uZluv/12evPNNyn0nNLNSilauHAhPfnkk3T99ddTjx496N1336WWlhZavHjxj3kpQRAuE2TeEAThLD9q8fHQQw/RpEmT6Morr2TxoqIiKi8vp3Hj2hXZBoOBRowYQVu2bHHfDRERWa1WamxsZP8EQbj8+DnnDSKZOwShM3PRj12WLFlCe/bsoZ07d8Lfysu/u+0cHc3rJERHR9PJk1iTgOi7579//OMfL7YbgiB0In7ueYNI5g5B6Mxc1J2PkpISeuSRR+j9998nPz8sOHYWjYYX0lFKQewss2fPpoaGhrZ/JSX4G2hBEDovl2LeIJK5QxA6Mxd152P37t1UWVlJubm5bTGn00mbNm2iV155hQoLC4nou28ysbHtopfKykr4VnMWg8FABgMKd9KykslkbDc9yd/GK7WmdEODpdMlKBw92YTrq4YTvMKktRbFWa56FJNGJSSzds++KZDjsKNINCqJm5FV1qLgKCwURYGuauyXMZG/7+szUNAY6I+iMaeNG4E5W1FcVH7yNMQ0Co2WTBH8XFrr8Ha3yxfNg9x1avpqrOJ5oAjFpf5GHB+6MB7rkYjCNacPiqp8DfzDr+dYFBWWHsHjMHw4N9YJ16GZ3GsvvgixYH/se3UxP69njh6FnEdn3gux1C58/BXmYWXK8kIUTlafQPH0B+/zKsAP3c9FsM0tzURvo3j6x3Ap5g2i888dw4f0J5Oh3aiq4gw3zmp1oMA3LhznCSOhALu1ji+G6qtRKBjgQchpC+TnZcaTaFK3eeVuiPk7uTjSWoF9L2/G+aTWQ9VlnZFP98qCc0CrDy726qz8wrW21kNObg5eR/WtKEz915KPWTspG02yDA48p1HB/FqOCEWBq58fVtbNLzwFsfoGfgy1Bg8VvvXYd1sEN07863++hZzt61Btee+V/Fz7OnBespXXQ6zodCnEdCb+g4Pxw/H4NXqYjy0aPr41wTiv7z6GfR9w9XUQO3yEj+VDx9r7aXdeuFD9ou58jBkzhg4cOEB5eXlt//r160e333475eXlUVpaGsXExNDq1avbtrHZbLRx40YaPHjwxbyUIAiXCTJvCILgzkXd+QgMDKQePXqwmMlkovDw8Lb4jBkzaN68eZSZmUmZmZk0b9488vf3p9tuu+3n67UgCJ0GmTcEQXDnZ6/t8thjj1FraytNnz6d6urqaODAgbRq1aqL/q2+IAj/Pci8IQj/XfzkxceGDRtYW6PR0Ny5c2nu3Lk/ddeCIFymyLwhCP/ddNiqtnl7j5BR3y7qC3ATQpk0KEqKCcUKhgdOoCjPXMdFYnVn6iFn6MgREKvOdhOX1WA1192f5EEsr3gVax86eBhyrh8xCGJ7du2HmG8UFzoO7JYDOU11WIk2Mom73o2++irIOXIGX6/7Fb0hZnVwoZqPE0W2KhbFpBNHT2HtmiKsvKksKPLzCcFqi5ogfv4bW1A8p/VQYtFq5bFb77se9+1CQdixXQWsnf8tHqvSE+hw6klUFR7KK0pmp6No2OGHfXdoeazViTn+gSgk27cHr4HTlbyv1TVcmGduxXPaWTicf4SM5wiCo0K5aDUsGJ03IxLwDouvBs9eZTmvghwVg9Wo+wzHazLATY8ZGIouqMEJeM24Kt2Elnrse6CHabzahcJRq4OLAZ2E41zrh8L37mm8qm1O796QkxyBx+FPC9Cl127gLq77DhVDjsODZtE/mLsouxS6KvtpUWgfERgCsdgonnfjPSMhp8+gXIj5+PDz88VT/4CcQAc6LVfUcAFoiwU/N/wsHipwu3Dei0/lx7m4HOf6nQfRfXnvYf6T9chQ7Gfv/jhuLTU4x2xbt5W1E8La+2Rz4Dx8PqSwnCAIgiAIXkUWH4IgCIIgeBVZfAiCIAiC4FU6rOZj9YpvSefT/mwuLIQ/p+vWF01trB6egXe/Ek1YjlZyE6nao2jcs2sXGv5MmnIFa5ccREdFlwP7UHucm5rVn6mAnLgU1Kso1QNi+w5wI5jj+WhQZfBFg7SSEq5ZOHbkDOSQB6Ol3lNGQqzVj+sy/INxu9ze/SH25Uefsnb5KdR8jJ44GWLlVfUQC0zkx8tgRNOvY0dQ66Aq+fk5FYX23QNGDIBYVAB/vWMafL6cdwC1PErhs/fwQP4sN1SP1UytzWgM1kfL++VuOkZElBKCRkt+kXiZV33NDYyiY0NYu7kF319nwerSksbZ/p4r3bRZTl985u4MRVO82CDUzwRGcr2OMwT3ldwL9SP1Vm5QZVZoApbSD8dBnIGbaZ3chqZZjhNoKuWnwzlABfFz6ojAHGpALZ3RxsdwbRGa8G1pRu2BsuLxMwa5vUctHr+AMNSiZPTg5oqbd+yBHIsZdUoaG15Hr730JGuXmbEy8exH/gSx4ye53icmEA3wEsLwPcfFcH3PASteW2+t2gAxowbfz7X3j2HtIg+mc8vWbYeY+6EJ0eE5HHvPnRA7tBvntPTELNZusbVfO1YHapnOh9z5EARBEATBq8jiQxAEQRAEryKLD0EQBEEQvIosPgRBEARB8CodVnCa3DWe9Lp28dPvfz+N/V2jbXbfhMIzsNKhjwlLeN/8+1+xdq+9aK7SKwdNZsqKiln7eAMKRxPCwyAWF8PFkNf8+gHIyRjZHWJv3jsPYlTOxUop6She0rlQ9HO6mptKnSrHCsAHi7Gq4U33/QpirnputnN0zzHI2bocRU9bd/GKtX0Hd4Wczz/6EmLZXdCE69iBA6zdtRcKi+N6JEBs57r1rH28Es+hw0O13W5deGXinr2xT2REU6BD+w5hnpmLxPxRZ0ixySkQqy3g57D4OIpl9S40Xxo2DouzTbiVm6sd2ryZd9FD1ePOQqOliay+7aLFzBx+fRdXo0i7+3Aci8FBeG2VHOIVcq2VHqqfalBkHKHjc1O9HeevpAQcr75m/v1Q74v7rq7FSsZxGShGjh2aztrJY1C0/88//BtioRYu0u6W2w1yjlSigDEhDt+P3cbfj8uE7+fGG1CsbnPyj6p+A7Cq+Wuvr4BYgBFFoS+/8R5r79qHhoGNHgTXyYGprP3g9AmYE4OfN/l5XFhfVI5mhFYPhm8RoShebbRyoXJwFIqGnR6qMWvdTOe6xeFnZTcP489cjoLdI6e5uLi0tr1tc4rJmCAIgiAIHRRZfAiCIAiC4FVk8SEIgiAIgleRxYcgCIIgCF6lwwpOb7n/egrwbxfwVdVzR8awoBDYpqUWXQojArEKpMWf52UPQydRpxZFO2FNvKLghBtuhJyThQUQS3TT9vgbsIKhzhQAscoWdK9L8OfCR73CU+ivxTXlDRO5M16jBYVE02NRXFp9BEWNtfXcLu/wFhSqUjAKqO76/a9Zu/8IFPpuXr8LYltXrIPY7TfewPuQj86PJzyIPdOTknhOSRnkHNqxF2L1NVyg2/OKnpAzfCwK5VrN6GSZGs63zR7SC3K+XroGYt98wV13Rw4cCDlHPVQKTu+HYlyLhgseT53hjrctls4rOE3LSiOjvn3uOFXOj4nyx/cWloBiYafVDDG9jgsKt61Hd8x/L98Csd5JfBKIz4yFnPh4nBf8W7lYfddavD76pmRD7HhFMcT69OKVuld+vgNyDh3Giqj9Mrn4ftVu7MPmQwcg5ueD4vveXflcq/VDgfSmTSiG37yHC8VjUvD4jZ2AzsQrPsH3WFbKBZM+Cj8j/LR47kcM5D8KWPr515BztAjn//gQLlQ1avE8D0hBh+ZAEwrfTf58HG3ej2PNzxddant24QLd28cOh5zGUyga1phRGB2g5Z+fkcb2zxur48LvZ8idD0EQBEEQvIosPgRBEARB8Cqy+BAEQRAEwavI4kMQBEEQBK/SYQWnyTHRFBjQXpq6tow7UVprsRTzkTwss/z5WhQFPf33p1nbNxid5MiAse2buftmbj90QT1zAsu479jORUj1HsSeOcMzIPbm289BzHy6irV1WizffXjbboidMdezdlZfFHvm70EhWa9EdAjsOZxvm9QnHXJCPJSWLsovZm1zUyXkdOuaCLGcrvdBTGvnYqzKtVWQQy1OCH2+nws5B/RHsWffK3pD7KibgC88DR0WTT7oihgZifalpRXcFTOkGh0Pv9mJrospydyBsMaJzpbZA/H9aENRzBZg4ucn0MTPs1aL5bw7C6bwEPI3tAu4z1RwUXHXdHT/bKzDa7Kpuh5i1np+3OIj0CX0cCkKWovcyrG77FiCfmACCoM/+fJz1o6IQKHlqUrcV0AYjrvdq/ex9sqPt0FOQxN+Hz1RV88Deg+umq0ehO9RIRA7XsZFjf6o86UjpXgta4iP4eqDJZDjq/D1as6gg3FaEi8J73DiuR995QiI6Xz4sfnmM/y8SYxH8W9gIB9vqhWvrSz3XyUQkbkZf3Dwn3dWs/ZXu1ZDjt2JLqt1TVxAu2r9t5AzsCt+Bll88EccSsN/jJEQ1S4sttgvfN6QOx+CIAiCIHgVWXwIgiAIguBVZPEhCIIgCIJX6bCaj9aaBvI9t5qilWs8tAqrIW7diGZUQX74/Gv9av7cf+KUSZCz4sOVEHvtqcWsfUW/rZAz5+lpENM4Ilj7cD4aQe34fDPE4rJQS2GM4M9y9cG4fuxrQC3Ktm+5cdZHiz+BHL0FTW0ayvG5Y8YwXtUyZzS+XksF6i1ObePPaf0T8Lm0EwvykisU32N4YhRrF5ZjZd0YLe7faOLnIsBD5cjQlBB8PT03J9u6AzUZvdJTILbkw08gVlbK389vE4dAzhN/eRJiMZncDMnuQM2HvQX1HY4gjJ0+wfU2r/7lI74fF5rsdRYsmhbSnFNZNi2ba2V0niRevmjyV16L2oN6t+tB44NVbX0M+Ny7upGf8yA/NLHKO4jmdmnZXJ9QVOFB2+SD57dXHGoPTuxzN0SLgBxLIM4Bh6v5dZsRhNtNGTAMYnU2nAPqrfz4XT0FKy7/Y+kSiBUd4rqWjJgsyHGZUZ/QNSsFYiFh3Pxs3wE0GtyxF43OBg7gJmNRgTGQE6HFcRSo48e0oBTnqpAQnPgiQ9CMTOPLPwdbWnH8afxwgB+v4uewsQ6NyG5+4G6IPf+H2RCLieVzoa+j/VqzO7E/50PufAiCIAiC4FVk8SEIgiAIgleRxYcgCIIgCF6lw2k+lPruuV1zC38manFra2yo+bDa0fvDpvBZWovb76wbmxp/MIeIyOHiRZCsDny9Rg+FeFqs/Hf/Fjs+FzN7eL0mD/uy6fhzTb0PHgdlxn65Fwqz2LAPLjs+M221euir27lobMTfybc247PjFgt/j00tqMfxpPlQelwj65v5sbHaUaNgceFxsChe8M7soYBaYzMed/fx6H4MiIiaPGxnc2DhLLuLn7OWVuxDUzMeU/9Gvp3dgTn2Vizo5yDsQ7Pb/t01HmfH+tnrsTNwtq+tVj7OHA5+THwsOMiazHgsza14jlvc9u3J18DhxHGnXHwM2zw8G2+14b7cbRasDhwrnrwYmq0e5iG3vtqcuC9Pz+w1xGMe++DhOFgdqPmwuW1rtmA/7R7mVafi49NTP21OnHNcLhz7Vofb+PAwT7j3k4io1a3QoKftPPXL/XjZPWzn+ZiiLsOi+LYuhe9P40Gv5X4ZO1z4udHcip+D7sedCN+jcp6j+fj/7+1C5g2N6mCzy+nTpykxEY2mBEHwPiUlJZSQkPDDiR0AmTsEoWNwIfNGh1t8uFwuKisro8DAQGpqaqLExEQqKSmhoKCgX7prF0VjY6P0/RdA+v7zoJSipqYmiouLIx+fzvF09uzcoZSipKSkDnEcL5aONAYuFun7L0NH6vvFzBsd7rGLj49P24rp7M/lgoKCfvGD+mORvv8ySN9/OsHBwT+c1IE4O3c0Nn53+7ijHMcfg/T9l0H6/tO50Hmjc3ylEQRBEAThskEWH4IgCIIgeJUOvfgwGAw0Z84cMhhQ9dvRkb7/Mkjfhc58HKXvvwzSd+/T4QSngiAIgiBc3nToOx+CIAiCIFx+yOJDEARBEASvIosPQRAEQRC8iiw+BEEQBEHwKrL4EARBEATBq3TYxcerr75Kqamp5OfnR7m5ufTNN9/80l0CNm3aRFdffTXFxcWRRqOhTz75hP1dKUVz586luLg4MhqNNHLkSDp06NAv01k35s+fT/3796fAwECKioqiKVOmUGFhIcvpqP1/7bXXKCcnp83Rb9CgQfTVV1+1/b2j9tsT8+fPJ41GQzNmzGiLdab+d0Rk7rh0yLzRMbgs5g3VAVmyZInS6XTqzTffVPn5+eqRRx5RJpNJnTx58pfuGmPFihXqySefVEuXLlVEpJYvX87+/txzz6nAwEC1dOlSdeDAAXXLLbeo2NhY1djY+Mt0+BzGjx+v3nnnHXXw4EGVl5enJk2apJKSklRzc3NbTkft/2effaa+/PJLVVhYqAoLC9UTTzyhdDqdOnjwYIfutzs7duxQKSkpKicnRz3yyCNt8c7S/46IzB2XFpk3fnkul3mjQy4+BgwYoKZNm8Zi2dnZatasWb9Qj34Y9wnE5XKpmJgY9dxzz7XFLBaLCg4OVq+//vov0MPvp7KyUhGR2rhxo1Kq8/U/NDRU/fOf/+w0/W5qalKZmZlq9erVasSIEW2TSGfpf0dF5g7vIvOGd7mc5o0O99jFZrPR7t27ady4cSw+btw42rJlyy/Uq4unqKiIysvL2fswGAw0YsSIDvk+GhoaiIgoLCyMiDpP/51OJy1ZsoTMZjMNGjSo0/T7oYceokmTJtGVV17J4p2l/x0RmTu8j8wb3uVymjc6XFXb6upqcjqdFB0dzeLR0dFUXl7+C/Xq4jnbV0/v4+TJk79El86LUopmzpxJQ4cOpR49ehBRx+//gQMHaNCgQWSxWCggIICWL19O3bp1a7vQOmq/iYiWLFlCe/bsoZ07d8LfOvpx78jI3OFdZN7wLpfbvNHhFh9n0Wg0rK2UglhnoDO8j4cffpj2799P3377Lfyto/a/S5culJeXR/X19bR06VKaOnUqbdy4se3vHbXfJSUl9Mgjj9CqVavIz8/vvHkdtf+dgcvl2HX09yHzhve4HOeNDvfYJSIigrRaLXxTqayshFVdRyYmJoaIqMO/j9/+9rf02Wef0fr16ykhIaEt3tH7r9frKSMjg/r160fz58+nXr160csvv9zh+717926qrKyk3Nxc8vX1JV9fX9q4cSP97W9/I19f37Y+dtT+d2Rk7vAeMm94l8tx3uhwiw+9Xk+5ubm0evVqFl+9ejUNHjz4F+rVxZOamkoxMTHsfdhsNtq4cWOHeB9KKXr44Ydp2bJltG7dOkpNTWV/7+j9d0cpRVartcP3e8yYMXTgwAHKy8tr+9evXz+6/fbbKS8vj9LS0jp0/zsyMndcemTe+GW4LOcN72tcf5izP5d76623VH5+vpoxY4YymUyquLj4l+4ao6mpSe3du1ft3btXEZF66aWX1N69e9t+1vfcc8+p4OBgtWzZMnXgwAF16623dpifPj344IMqODhYbdiwQZ05c6btX0tLS1tOR+3/7Nmz1aZNm1RRUZHav3+/euKJJ5SPj49atWpVh+73+ThXta5U5+t/R0LmjkuLzBsdh84+b3TIxYdSSv3jH/9QycnJSq/Xq759+7b9lKsjsX79ekVE8G/q1KlKqe9+/jRnzhwVExOjDAaDGj58uDpw4MAv2+n/j6d+E5F655132nI6av/vueeetrERGRmpxowZ0zaBKNVx+30+3CeRztb/jobMHZcOmTc6Dp193tAopZT37rMIgiAIgvDfTofTfAiCIAiCcHkjiw9BEARBELyKLD4EQRAEQfAqsvgQBEEQBMGryOJDEARBEASvIosPQRAEQRC8iiw+BEEQBEHwKrL4EARBEATBq8jiQxAEQRAEryKLD0EQBEEQvIosPgRBEARB8Cr/D2UlneUzaVO4AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, [ax1, ax2] = plt.subplots(1, 2)\n",
        "idx_negative = torch.where(label_train.squeeze() == 0)[0]\n",
        "idx_negative = idx_negative[torch.randperm(len(idx_negative))[0]]\n",
        "\n",
        "idx_positive = torch.where(label_train.squeeze() == 1)[0]\n",
        "idx_positive = idx_positive[torch.randperm(len(idx_positive))[0]]\n",
        "\n",
        "print('index for no metastatic tissue:', idx_negative.item())\n",
        "print('index for metastatic tissue:', idx_positive.item())\n",
        "\n",
        "ax1.imshow(img_train[idx_negative].permute(1, 2, 0))\n",
        "ax1.set_title('no metastatic tissue')\n",
        "ax2.imshow(img_train[idx_positive].permute(1, 2, 0))\n",
        "ax2.set_title('metastatic tissue')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdj_paAtcjTl"
      },
      "source": [
        "We load a pretrained `VGG11`, inspect its architecture and gather some computational information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKHf1__JtM6x",
        "outputId": "cb39ebaf-931b-4bdd-d79d-4387495b607b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/manuel/miniforge3/envs/ml/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/manuel/miniforge3/envs/ml/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to /Users/manuel/.cache/torch/hub/checkpoints/vgg11_bn-6002323d.pth\n",
            "100%|██████████| 507M/507M [00:27<00:00, 19.2MB/s] \n",
            "/Users/manuel/miniforge3/envs/ml/lib/python3.9/site-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/Users/manuel/miniforge3/envs/ml/lib/python3.9/site-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "VGG                                      [128, 1000]               --\n",
              "├─Sequential: 1-1                        [128, 512, 1, 1]          --\n",
              "│    └─Conv2d: 2-1                       [128, 64, 48, 48]         1,792\n",
              "│    └─BatchNorm2d: 2-2                  [128, 64, 48, 48]         128\n",
              "│    └─ReLU: 2-3                         [128, 64, 48, 48]         --\n",
              "│    └─MaxPool2d: 2-4                    [128, 64, 24, 24]         --\n",
              "│    └─Conv2d: 2-5                       [128, 128, 24, 24]        73,856\n",
              "│    └─BatchNorm2d: 2-6                  [128, 128, 24, 24]        256\n",
              "│    └─ReLU: 2-7                         [128, 128, 24, 24]        --\n",
              "│    └─MaxPool2d: 2-8                    [128, 128, 12, 12]        --\n",
              "│    └─Conv2d: 2-9                       [128, 256, 12, 12]        295,168\n",
              "│    └─BatchNorm2d: 2-10                 [128, 256, 12, 12]        512\n",
              "│    └─ReLU: 2-11                        [128, 256, 12, 12]        --\n",
              "│    └─Conv2d: 2-12                      [128, 256, 12, 12]        590,080\n",
              "│    └─BatchNorm2d: 2-13                 [128, 256, 12, 12]        512\n",
              "│    └─ReLU: 2-14                        [128, 256, 12, 12]        --\n",
              "│    └─MaxPool2d: 2-15                   [128, 256, 6, 6]          --\n",
              "│    └─Conv2d: 2-16                      [128, 512, 6, 6]          1,180,160\n",
              "│    └─BatchNorm2d: 2-17                 [128, 512, 6, 6]          1,024\n",
              "│    └─ReLU: 2-18                        [128, 512, 6, 6]          --\n",
              "│    └─Conv2d: 2-19                      [128, 512, 6, 6]          2,359,808\n",
              "│    └─BatchNorm2d: 2-20                 [128, 512, 6, 6]          1,024\n",
              "│    └─ReLU: 2-21                        [128, 512, 6, 6]          --\n",
              "│    └─MaxPool2d: 2-22                   [128, 512, 3, 3]          --\n",
              "│    └─Conv2d: 2-23                      [128, 512, 3, 3]          2,359,808\n",
              "│    └─BatchNorm2d: 2-24                 [128, 512, 3, 3]          1,024\n",
              "│    └─ReLU: 2-25                        [128, 512, 3, 3]          --\n",
              "│    └─Conv2d: 2-26                      [128, 512, 3, 3]          2,359,808\n",
              "│    └─BatchNorm2d: 2-27                 [128, 512, 3, 3]          1,024\n",
              "│    └─ReLU: 2-28                        [128, 512, 3, 3]          --\n",
              "│    └─MaxPool2d: 2-29                   [128, 512, 1, 1]          --\n",
              "├─AdaptiveAvgPool2d: 1-2                 [128, 512, 7, 7]          --\n",
              "├─Sequential: 1-3                        [128, 1000]               --\n",
              "│    └─Linear: 2-30                      [128, 4096]               102,764,544\n",
              "│    └─ReLU: 2-31                        [128, 4096]               --\n",
              "│    └─Dropout: 2-32                     [128, 4096]               --\n",
              "│    └─Linear: 2-33                      [128, 4096]               16,781,312\n",
              "│    └─ReLU: 2-34                        [128, 4096]               --\n",
              "│    └─Dropout: 2-35                     [128, 4096]               --\n",
              "│    └─Linear: 2-36                      [128, 1000]               4,097,000\n",
              "==========================================================================================\n",
              "Total params: 132,868,840\n",
              "Trainable params: 132,868,840\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 59.87\n",
              "==========================================================================================\n",
              "Input size (MB): 3.54\n",
              "Forward/backward pass size (MB): 707.76\n",
              "Params size (MB): 531.48\n",
              "Estimated Total Size (MB): 1242.78\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "net = torchvision.models.vgg11_bn(pretrained='True')\n",
        "\n",
        "summary(net, (128, 3, 48, 48))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XfC5stkxcjTv"
      },
      "source": [
        "## Task 0 (15 points): Modify a pretrained VGG11_BN network for the given training data\n",
        "Complete the function below, which returns a VGG11-Net with its architecture modified accordingly to match the tupac16 dataset.\n",
        "+ Replace the layer `net.avgpool` with an adaptive average pool of output size $1\\times1$\n",
        "+ Create a new classifier as `nn.Sequential` with two linear layers ($512\\times256$ and $256\\times2$) including one ReLU and no batch-norm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8pmjxtAZcjTw"
      },
      "outputs": [],
      "source": [
        "def tupac16_vgg11():\n",
        "    net = torchvision.models.vgg11_bn(pretrained='True')\n",
        "    net.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    net.classifier = nn.Sequential(\n",
        "        nn.Linear(512,256),\n",
        "        nn.Linear(256,2),\n",
        "        nn.ReLU() #no batch-norm? -> YES READ ABOVE\n",
        "    )\n",
        "\n",
        "    return net"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8H5XnIXmcjTy"
      },
      "source": [
        "Check the reduced parameter count using `summary` from `torchinfo`. Your should obtain about $9\\,357\\,826$ parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eomZ9IGicjTz",
        "outputId": "1625b938-209b-44f1-da19-64ed76a8cef0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "VGG                                      --\n",
              "├─Sequential: 1-1                        --\n",
              "│    └─Conv2d: 2-1                       1,792\n",
              "│    └─BatchNorm2d: 2-2                  128\n",
              "│    └─ReLU: 2-3                         --\n",
              "│    └─MaxPool2d: 2-4                    --\n",
              "│    └─Conv2d: 2-5                       73,856\n",
              "│    └─BatchNorm2d: 2-6                  256\n",
              "│    └─ReLU: 2-7                         --\n",
              "│    └─MaxPool2d: 2-8                    --\n",
              "│    └─Conv2d: 2-9                       295,168\n",
              "│    └─BatchNorm2d: 2-10                 512\n",
              "│    └─ReLU: 2-11                        --\n",
              "│    └─Conv2d: 2-12                      590,080\n",
              "│    └─BatchNorm2d: 2-13                 512\n",
              "│    └─ReLU: 2-14                        --\n",
              "│    └─MaxPool2d: 2-15                   --\n",
              "│    └─Conv2d: 2-16                      1,180,160\n",
              "│    └─BatchNorm2d: 2-17                 1,024\n",
              "│    └─ReLU: 2-18                        --\n",
              "│    └─Conv2d: 2-19                      2,359,808\n",
              "│    └─BatchNorm2d: 2-20                 1,024\n",
              "│    └─ReLU: 2-21                        --\n",
              "│    └─MaxPool2d: 2-22                   --\n",
              "│    └─Conv2d: 2-23                      2,359,808\n",
              "│    └─BatchNorm2d: 2-24                 1,024\n",
              "│    └─ReLU: 2-25                        --\n",
              "│    └─Conv2d: 2-26                      2,359,808\n",
              "│    └─BatchNorm2d: 2-27                 1,024\n",
              "│    └─ReLU: 2-28                        --\n",
              "│    └─MaxPool2d: 2-29                   --\n",
              "├─AdaptiveAvgPool2d: 1-2                 --\n",
              "├─Sequential: 1-3                        --\n",
              "│    └─Linear: 2-30                      131,328\n",
              "│    └─Linear: 2-31                      514\n",
              "│    └─ReLU: 2-32                        --\n",
              "=================================================================\n",
              "Total params: 9,357,826\n",
              "Trainable params: 9,357,826\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tupac16_vgg11()\n",
        "summary(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HVeA6LHccjTz"
      },
      "source": [
        "## Task1 (25 points): Fine tuning\n",
        "Fine-tune this network for 16 sub-epochs on the tupac16 dataset. One sub-epoch is defined as a random quarter of the training pathes. Use `torch.randperm` to generate the needed indices for every epoch. The batch size should be 128. Choose Adam as an optimizer with an initial learning rate of 0.0005 and an exponential learning rate scheduler with `gamma=0.9`. After training, evaluate the model on the test data. It should yield an accuracy about $94\\%$.\n",
        "\n",
        "**Note:** Task 2 and 3 can be performed independently, but you should store each trained network under a new filename (for comparisons). In the following all techniques should only be applied to the feature-part of the network (and not the classifier layers).\n",
        "\n",
        "**Hint**: If you struggle with implementing of the training routine, have a look at the previous exercises."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633,
          "referenced_widgets": [
            "493869f4f7634ed695af66d597c148b5",
            "234732794167490593d69972c3f79e72",
            "45bc6f7311664b1d9117fb3d0b9c64c7",
            "f4dff813c27d4693be4316a308bd6ba6",
            "158f2152070940bc8be6d75210abc3b1",
            "d87c60e759f74aaa9b08436d7a6a8006",
            "bf2245da5d414263a493cac2d519dbd7",
            "9d5e0dbc15024c77af6ee872e6ce0824",
            "76afb3c6910749409ad8bd19c7907533",
            "514b7c10e84e408e9a7b69157c391700",
            "ff8b1f081ad5443386af49946d53efaa"
          ]
        },
        "id": "mqKw4fzMVd4Q",
        "outputId": "2a45f356-0c0f-4e03-e537-e4ebed6b2cc4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3aa18d53377d42aa9929538b83e6a1b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/16 [00:00<?, ?epoch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 (train) -- loss: 0.3554 accuracy: 0.8287\n",
            "Epoch 0 (valid) -- loss: 0.3108 accuracy: 0.8727\n",
            "Epoch 1 (train) -- loss: 0.2532 accuracy: 0.8950\n",
            "Epoch 1 (valid) -- loss: 0.3060 accuracy: 0.8712\n",
            "Epoch 2 (train) -- loss: 0.2199 accuracy: 0.9133\n",
            "Epoch 2 (valid) -- loss: 0.2363 accuracy: 0.9057\n",
            "Epoch 3 (train) -- loss: 0.1870 accuracy: 0.9283\n",
            "Epoch 3 (valid) -- loss: 0.2367 accuracy: 0.9081\n",
            "Epoch 4 (train) -- loss: 0.1599 accuracy: 0.9404\n",
            "Epoch 4 (valid) -- loss: 0.2458 accuracy: 0.9109\n",
            "Epoch 5 (train) -- loss: 0.1425 accuracy: 0.9485\n",
            "Epoch 5 (valid) -- loss: 0.2450 accuracy: 0.9166\n",
            "Epoch 6 (train) -- loss: 0.1204 accuracy: 0.9549\n",
            "Epoch 6 (valid) -- loss: 0.2647 accuracy: 0.8958\n",
            "Epoch 7 (train) -- loss: 0.1063 accuracy: 0.9622\n",
            "Epoch 7 (valid) -- loss: 0.2074 accuracy: 0.9260\n",
            "Epoch 8 (train) -- loss: 0.0886 accuracy: 0.9693\n",
            "Epoch 8 (valid) -- loss: 0.2074 accuracy: 0.9285\n",
            "Epoch 9 (train) -- loss: 0.0726 accuracy: 0.9753\n",
            "Epoch 9 (valid) -- loss: 0.1984 accuracy: 0.9356\n",
            "Epoch 10 (train) -- loss: 0.0570 accuracy: 0.9810\n",
            "Epoch 10 (valid) -- loss: 0.1993 accuracy: 0.9374\n",
            "Epoch 11 (train) -- loss: 0.0508 accuracy: 0.9830\n",
            "Epoch 11 (valid) -- loss: 0.2202 accuracy: 0.9323\n",
            "Epoch 12 (train) -- loss: 0.0450 accuracy: 0.9857\n",
            "Epoch 12 (valid) -- loss: 0.1970 accuracy: 0.9377\n",
            "Epoch 13 (train) -- loss: 0.0380 accuracy: 0.9883\n",
            "Epoch 13 (valid) -- loss: 0.2130 accuracy: 0.9390\n",
            "Epoch 14 (train) -- loss: 0.0296 accuracy: 0.9910\n",
            "Epoch 14 (valid) -- loss: 0.2109 accuracy: 0.9388\n",
            "Epoch 15 (train) -- loss: 0.0228 accuracy: 0.9932\n",
            "Epoch 15 (valid) -- loss: 0.2096 accuracy: 0.9428\n"
          ]
        }
      ],
      "source": [
        "# Task1 - Training loop # hier war nichts gegeben, hab ich von ex 4 übernommen\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "test_dataset = TensorDataset(img_test, label_test[0])\n",
        "dl_test = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 16\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= 0.0005)\n",
        "\n",
        "# learning rate scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "# criterion\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# for reproducibility (do not change)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# statistics\n",
        "train_loss = torch.zeros(num_epochs, device=device)\n",
        "train_acc = torch.zeros_like(train_loss)\n",
        "\n",
        "test_loss = torch.zeros_like(train_loss)\n",
        "test_acc = torch.zeros_like(train_loss)\n",
        "\n",
        "# for num_epochs\n",
        "for epoch in trange(num_epochs, unit='epoch'):\n",
        "\n",
        "    # Generate random indices for a quarter of the training paths\n",
        "    quarter = len(img_train) // 4\n",
        "    indices = torch.randperm(len(img_train))[:quarter]\n",
        "\n",
        "    # Subset the dataset using the generated indices\n",
        "    train_dataset = TensorDataset(img_train, label_train[0])\n",
        "\n",
        "    subset_dataset = torch.utils.data.Subset(train_dataset, indices)\n",
        "\n",
        "    # Create a data loader for the subset of data\n",
        "    dl_train = DataLoader(subset_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "    # train mode\n",
        "    model.train()\n",
        "\n",
        "    # for each mini-batch\n",
        "    for input, target in dl_train:\n",
        "        input = input.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        # todo\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # todo\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        train_loss[epoch] += loss.detach()\n",
        "        train_acc[epoch] += torch.mean((torch.argmax(output, dim=-1) == target).float())\n",
        "\n",
        "    # update learning rate\n",
        "    # todo\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    train_loss[epoch] /= len(dl_train)\n",
        "    train_acc[epoch] /= len(dl_train)\n",
        "\n",
        "    # output\n",
        "    tqdm.write('Epoch {} (train) -- loss: {:.4f} accuracy: {:.4f}'.format(epoch, train_loss[epoch].item(), train_acc[epoch].item()))\n",
        "\n",
        "    # validate\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # eval mode\n",
        "        model.eval()\n",
        "\n",
        "        # for each mini-batch\n",
        "        for input, target in dl_test:\n",
        "            input = input.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # forward\n",
        "            # todo\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # statistics\n",
        "            test_loss[epoch] += loss.detach()\n",
        "            test_acc[epoch] += torch.mean((torch.argmax(output, dim=-1) == target).float())\n",
        "\n",
        "        test_loss[epoch] /= len(dl_test)\n",
        "        test_acc[epoch] /= len(dl_test)\n",
        "\n",
        "        # output\n",
        "        tqdm.write('Epoch {} (valid) -- loss: {:.4f} accuracy: {:.4f}'.format(epoch, test_loss[epoch].item(), test_acc[epoch].item()))\n",
        "\n",
        "# save trained network as tupac16_ex1.pt\n",
        "torch.save(model, 'tupac16_ex1.pth')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iFs7e-4dcjT0"
      },
      "source": [
        "## Task 2 (60 points): Network Pruning through increased Sparsity\n",
        "+ Start with the same modified, pre-trained (not fine-tuned) vgg11_bn as before by calling your `tupac16_vgg11` method.\n",
        "+ Reuse the training routine from above.\n",
        "+ Add a sparsity promoting L1-loss (sum of absolute values) with a weight factor of 0.04 to the classification loss on the weights and bias of each BatchNorm2d.\n",
        "    + Therefor iterate over all modules of the net using `modules()` and determine the layer type using `isinstance()`\n",
        "+ Retrain the network.\n",
        "+ Evaluate its test accuracy (will drop slightly to ~89%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def l1_sparse_loss(layer):\n",
        "    #print('l1_sparse_loss:', torch.sum(abs(layer.weight))+torch.sum(abs(layer.bias)))\n",
        "    return torch.sum(abs(layer.weight)) + torch.sum(abs(layer.bias))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "nLFzc3vmm-qi"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c04414eff33543088a8213a4ecdb29fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/16 [00:00<?, ?epoch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 (train) -- loss: 74.5240 accuracy: 0.8242\n",
            "Epoch 0 (valid) -- loss: 0.3078 accuracy: 0.8747\n",
            "Epoch 1 (train) -- loss: 61.6939 accuracy: 0.8900\n",
            "Epoch 1 (valid) -- loss: 0.2757 accuracy: 0.8929\n",
            "Epoch 2 (train) -- loss: 50.7379 accuracy: 0.9064\n",
            "Epoch 2 (valid) -- loss: 0.3040 accuracy: 0.8790\n",
            "Epoch 3 (train) -- loss: 41.5688 accuracy: 0.9108\n",
            "Epoch 3 (valid) -- loss: 0.2881 accuracy: 0.8709\n",
            "Epoch 4 (train) -- loss: 34.1827 accuracy: 0.9135\n",
            "Epoch 4 (valid) -- loss: 0.3173 accuracy: 0.8607\n",
            "Epoch 5 (train) -- loss: 28.6668 accuracy: 0.9086\n",
            "Epoch 5 (valid) -- loss: 0.3024 accuracy: 0.8766\n",
            "Epoch 6 (train) -- loss: 24.7862 accuracy: 0.9102\n",
            "Epoch 6 (valid) -- loss: 0.2555 accuracy: 0.8997\n",
            "Epoch 7 (train) -- loss: 22.0559 accuracy: 0.9117\n",
            "Epoch 7 (valid) -- loss: 0.4328 accuracy: 0.8336\n",
            "Epoch 8 (train) -- loss: 20.0187 accuracy: 0.9127\n",
            "Epoch 8 (valid) -- loss: 0.2636 accuracy: 0.8936\n",
            "Epoch 9 (train) -- loss: 18.4022 accuracy: 0.9167\n",
            "Epoch 9 (valid) -- loss: 0.2381 accuracy: 0.9050\n",
            "Epoch 10 (train) -- loss: 17.0757 accuracy: 0.9236\n",
            "Epoch 10 (valid) -- loss: 0.2515 accuracy: 0.9023\n",
            "Epoch 11 (train) -- loss: 15.9723 accuracy: 0.9207\n",
            "Epoch 11 (valid) -- loss: 0.3228 accuracy: 0.8749\n",
            "Epoch 12 (train) -- loss: 15.0110 accuracy: 0.9221\n",
            "Epoch 12 (valid) -- loss: 0.2437 accuracy: 0.9017\n",
            "Epoch 13 (train) -- loss: 14.1723 accuracy: 0.9269\n",
            "Epoch 13 (valid) -- loss: 0.3043 accuracy: 0.8796\n",
            "Epoch 14 (train) -- loss: 13.4514 accuracy: 0.9289\n",
            "Epoch 14 (valid) -- loss: 0.2605 accuracy: 0.8956\n",
            "Epoch 15 (train) -- loss: 12.8116 accuracy: 0.9330\n",
            "Epoch 15 (valid) -- loss: 0.3072 accuracy: 0.8794\n"
          ]
        }
      ],
      "source": [
        "# Task 2\n",
        "model = tupac16_vgg11()\n",
        "\n",
        "# Task1 - Training loop # hier war nichts gegeben, hab ich von ex 4 übernommen\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "test_dataset = TensorDataset(img_test, label_test[0])\n",
        "dl_test = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 16\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= 0.0005)\n",
        "\n",
        "# learning rate scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "# criterion\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# for reproducibility (do not change)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# statistics\n",
        "train_loss = torch.zeros(num_epochs, device=device)\n",
        "train_acc = torch.zeros_like(train_loss)\n",
        "\n",
        "test_loss = torch.zeros_like(train_loss)\n",
        "test_acc = torch.zeros_like(train_loss)\n",
        "\n",
        "# for num_epochs\n",
        "for epoch in trange(num_epochs, unit='epoch'):\n",
        "\n",
        "    # Generate random indices for a quarter of the training paths\n",
        "    quarter = len(img_train) // 4\n",
        "    indices = torch.randperm(len(img_train))[:quarter]\n",
        "\n",
        "    # Subset the dataset using the generated indices\n",
        "    train_dataset = TensorDataset(img_train, label_train[0])\n",
        "\n",
        "    subset_dataset = torch.utils.data.Subset(train_dataset, indices)\n",
        "\n",
        "    # Create a data loader for the subset of data\n",
        "    dl_train = DataLoader(subset_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "    # train mode\n",
        "    model.train()\n",
        "\n",
        "    # for each mini-batch\n",
        "    for input, target in dl_train:\n",
        "        input = input.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        # todo\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # todo\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "        for i in model.modules():\n",
        "             if isinstance(i, nn.BatchNorm2d):\n",
        "                loss += 0.04 * l1_sparse_loss(i)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        train_loss[epoch] += loss.detach()\n",
        "        train_acc[epoch] += torch.mean((torch.argmax(output, dim=-1) == target).float())\n",
        "\n",
        "    # update learning rate\n",
        "    # todo\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    train_loss[epoch] /= len(dl_train)\n",
        "    train_acc[epoch] /= len(dl_train)\n",
        "\n",
        "    # output\n",
        "    tqdm.write('Epoch {} (train) -- loss: {:.4f} accuracy: {:.4f}'.format(epoch, train_loss[epoch].item(), train_acc[epoch].item()))\n",
        "\n",
        "    # validate\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # eval mode\n",
        "        model.eval()\n",
        "\n",
        "        # for each mini-batch\n",
        "        for input, target in dl_test:\n",
        "            input = input.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # forward\n",
        "            # todo\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "            for i in model.modules():\n",
        "             if isinstance(i, nn.BatchNorm2d):\n",
        "                loss += 0.04 * l1_sparse_loss(i)\n",
        "\n",
        "            # statistics\n",
        "            test_loss[epoch] += loss.detach()\n",
        "            test_acc[epoch] += torch.mean((torch.argmax(output, dim=-1) == target).float())\n",
        "\n",
        "        test_loss[epoch] /= len(dl_test)\n",
        "        test_acc[epoch] /= len(dl_test)\n",
        "\n",
        "        # output\n",
        "        tqdm.write('Epoch {} (valid) -- loss: {:.4f} accuracy: {:.4f}'.format(epoch, test_loss[epoch].item(), test_acc[epoch].item()))\n",
        "\n",
        "# save trained network as tupac16_ex1.pt\n",
        "torch.save(model, 'tupac16_ex2.pth')\n",
        "\n",
        "# todo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr5wVHyMcjT2"
      },
      "source": [
        "Write a function that determines a threshold for input/output neurons to be set to zero (the ones which have been reduced in absolute value using the sparsity constraint). You can use the function `topk`, which outputs both the values and indices sorted around a chosen quantile/percentile. Here we simply use the median to set 50% of values to zero.\n",
        "\n",
        "When applied correctly (as incoming & outgoing mask) for each Conv2d layer, it reduces the nonzero parameters by ~75% (the first incoming & last outgoing Conv2d are not masked).\n",
        "Note that BatchNorm has four tensors and two index masks have to be applied as follows:\n",
        "\n",
        "`B = A[idx_next,:,:,:][:,idx_prev,:,:]`\n",
        "\n",
        "Now you can replace all Conv2d and BatchNorm2d layers with smaller filters (and copy their weights) so that we have the following sequence of channels: 3, 32, 64, (2x)128, (3x)256, 512.\n",
        "Evaluate the slimmed network (you could observe a slight improvement to ~92%) and confirm that the required computations are reduced to 12 GFlops."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "y0DMYXwivPPe",
        "outputId": "cfe4bdd8-410d-4de3-ffcf-614d0c63bf45"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[39], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m net \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(model_name)\n\u001b[1;32m     10\u001b[0m net\u001b[39m.\u001b[39meval()\n\u001b[0;32m---> 11\u001b[0m net\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m     13\u001b[0m mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     14\u001b[0m idx_prev \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mcuda()\n",
            "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    889\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \n\u001b[1;32m    891\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
            "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
            "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    889\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \n\u001b[1;32m    891\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
            "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "# task 2 Network slimming (construct lean filters)\n",
        "\n",
        "sparsity_s = 0.04\n",
        "ternary = False\n",
        "\n",
        "model_name = 'tupac16_ex2.pt'\n",
        "\n",
        "net = torch.load(model_name)\n",
        "\n",
        "net.eval()\n",
        "net.to(device)\n",
        "\n",
        "mask = torch.ones(3).to(device)\n",
        "idx_prev = torch.arange(3).long().to(device)\n",
        "q75 = 0.5\n",
        "print('#params before',countParameters(net.features))\n",
        "print('#features sparsity',countSparsity(net.features))\n",
        "\n",
        "\n",
        "for c in range(len(net.features)-2):\n",
        "    if isinstance(net.features[c], nn.Conv2d):\n",
        "        if(c==25):\n",
        "            q75=1\n",
        "        # todo\n",
        "\n",
        "\n",
        "# evaluation for task 2\n",
        "\n",
        "print('#params after',countParameters(net.features))\n",
        "print('#features sparsity',countSparsity(net.features))\n",
        "\n",
        "idx_epoch = torch.arange(16384).view(128,-1)\n",
        "val_acc = 0\n",
        "\n",
        "for iter in range(idx_epoch.size(1)):\n",
        "    idx_iter = idx_epoch[:,iter]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        #forward path and loss\n",
        "        outputs = net(img_test[idx_iter,:,:,:].cuda())\n",
        "    val_acc += torch.sum((outputs.argmax(1).cpu()==label_test[0,idx_iter]).float())/16384.0\n",
        "\n",
        "print(val_acc)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VJvTp6YZcjT4"
      },
      "source": [
        "## Bonus Task - Ternary Nets:\n",
        "Start with the same modified, pre-trained (not fine-tuned) vgg11_bn as before. Finally, we want to explore, how the memory storage can be reduced with little loss. Here a ternary weight approximation will be used for which we first estimate a per-channel $\\Delta$ for each weight in Conv2d given the rule-of-thumb below.\n",
        "\n",
        "$\\begin{align}\n",
        "    \\Delta &= \\frac{0.7}{n}\\sum^n_{i=1}|W_i|\\\\\n",
        "    \\tilde{W}_i&=\n",
        "    \\begin{cases}\n",
        "        +1, &\\text{ if } W_i > \\Delta\\\\\n",
        "        0,  &\\text{ if } |W_i| \\leq \\Delta\\\\\n",
        "        -1,  &\\text{ else }\n",
        "    \\end{cases}\\\\\n",
        "    n_\\Delta &= \\sum_i|\\tilde{W}_i|\\\\\n",
        "    \\alpha &= \\frac{1}{n_\\Delta}\\sum_i|\\tilde{W}_i||W_i|\n",
        "\\end{align}$\n",
        "\n",
        "Tip: after calculating the absolute values the mean has to be computed over all but the 0-th dimension.\n",
        "The obtained ternary weights have lost their magnitude, therefore the parameter $\\alpha$ (again per-channel) is computed and multiplied with the weight tensor.\n",
        "\n",
        "Test your function with the check implemented below. For a $128\\times64\\times3\\times3$ kernel the number of unique entries is reduced from more than 70 thousand to just 257 ($2 \\cdot 128 + 1$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4ay90rCv3gi"
      },
      "outputs": [],
      "source": [
        "# template for function in bonus task\n",
        "def approx_weights(w_in,flag=True):\n",
        "    if(flag):\n",
        "        with torch.no_grad():\n",
        "            a,b,c,d = w_in.size()\n",
        "            delta = # todo\n",
        "            alpha = # todo\n",
        "            w_out = # todo\n",
        "    else:\n",
        "        w_out = w_in\n",
        "    return w_out\n",
        "\n",
        "# check the number of unique values before/after ternary approximation\n",
        "w_in = net.features[8].weight.clone().detach()\n",
        "w_approx = approx_weights(w_in,True)\n",
        "print('#unique',len(np.unique(w_in.data.cpu().flatten().numpy())))\n",
        "print('#unique',len(np.unique(w_approx.data.cpu().flatten().numpy())))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w2riL-ZFcjUB"
      },
      "source": [
        "To effectively train a network with weight quantisation, it is important to only use the ternary weights during forward/backward path, but update their gradients in full precision.\n",
        "\n",
        "Implement a loop that stores full precision weights in a list of tensors and replaces the `.data` values with their approximation just before calling the forward pass (and zero_grad).\n",
        "Reassign these backup copies after `loss.backward()` and `before optimizer.step()`. Retrain your network and take care to perform the weight quantisation the same way during test evaluation. The test accuracy should be around 85-90% during the epochs.\n",
        "\n",
        "**Tip:** you could use `.pop(0)` to (iteratively) access and remove the first object of a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnyU-fjIcjUB"
      },
      "outputs": [],
      "source": [
        "# todo"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "158f2152070940bc8be6d75210abc3b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "234732794167490593d69972c3f79e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d87c60e759f74aaa9b08436d7a6a8006",
            "placeholder": "​",
            "style": "IPY_MODEL_bf2245da5d414263a493cac2d519dbd7",
            "value": "100%"
          }
        },
        "45bc6f7311664b1d9117fb3d0b9c64c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d5e0dbc15024c77af6ee872e6ce0824",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76afb3c6910749409ad8bd19c7907533",
            "value": 16
          }
        },
        "493869f4f7634ed695af66d597c148b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_234732794167490593d69972c3f79e72",
              "IPY_MODEL_45bc6f7311664b1d9117fb3d0b9c64c7",
              "IPY_MODEL_f4dff813c27d4693be4316a308bd6ba6"
            ],
            "layout": "IPY_MODEL_158f2152070940bc8be6d75210abc3b1"
          }
        },
        "514b7c10e84e408e9a7b69157c391700": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76afb3c6910749409ad8bd19c7907533": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d5e0dbc15024c77af6ee872e6ce0824": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf2245da5d414263a493cac2d519dbd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d87c60e759f74aaa9b08436d7a6a8006": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4dff813c27d4693be4316a308bd6ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_514b7c10e84e408e9a7b69157c391700",
            "placeholder": "​",
            "style": "IPY_MODEL_ff8b1f081ad5443386af49946d53efaa",
            "value": " 16/16 [02:41&lt;00:00, 10.13s/epoch]"
          }
        },
        "ff8b1f081ad5443386af49946d53efaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
